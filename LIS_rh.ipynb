{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPEN-CV PROJECT: LIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Holistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    \n",
    "def draw_landmarks_custom(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,255),thickness=1, circle_radius=1),\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,255),thickness=1, circle_radius=1),\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10),thickness=1, circle_radius=1),\n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121),thickness=1, circle_radius=1),\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,0),thickness=3, circle_radius=5),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,0),thickness=3, circle_radius=5),\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,0),thickness=3, circle_radius=5),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,0),thickness=3, circle_radius=5),\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, \n",
    "                          min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        black = np.zeros((1080, 1920, 3))\n",
    "        ret, frame = cap.read()\n",
    "        #frame = cv2.flip(frame,1)\n",
    "        \n",
    "        # make detection\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        points_rh_x = []\n",
    "        points_rh_y = []\n",
    "        if results.right_hand_landmarks:\n",
    "            for i in range(21):\n",
    "                points_rh_x.append(results.right_hand_landmarks.landmark[i].x)\n",
    "                points_rh_y.append(results.right_hand_landmarks.landmark[i].y)\n",
    "                        \n",
    "        draw_landmarks_custom(frame, results)\n",
    "        \n",
    "        cv2.imshow('LIS', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract point for training and prediction\n",
    "* Calculate x and y min/max\n",
    "* Extract points from results\n",
    "* Normalize between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_detection(results):\n",
    "    \n",
    "    xMax = max([i.x for i in results.right_hand_landmarks.landmark])\n",
    "    xMin = min([i.x for i in results.right_hand_landmarks.landmark])\n",
    "    yMax = max([i.y for i in results.right_hand_landmarks.landmark])\n",
    "    yMin = min([i.y for i in results.right_hand_landmarks.landmark])\n",
    "    \n",
    "    rh = np.array([[points.x, points.y, points.z] for points in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "\n",
    "    for i in np.arange(0, 63, 3):\n",
    "        rh[i]=(rh[i]-xMin)/(xMax-xMin)\n",
    "    for i in np.arange(1, 63, 3):\n",
    "        rh[i]=(rh[i]-yMin)/(yMax-yMin)\n",
    "\n",
    "    # lh = np.array([[points.x, points.y, points.z] for points in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    # po = np.array([[points.x, points.y, points.z] for points in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(99)\n",
    "    # return np.concatenate([lh, rh, po])\n",
    "\n",
    "    return rh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Folders for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('LIS_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set number of output and number of sample for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(['a', 'b', 'c']) # put the entire alphabet in the future\n",
    "no_sequences = 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "#no_sequences = no_sequences+1\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "    for label in labels:\n",
    "        for id in range(no_sequences):\n",
    "    \n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # make detection\n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "            draw_landmarks_custom(frame, results)\n",
    "\n",
    "            if id == 0:\n",
    "                cv2.putText(frame, 'STARTING COLLECTION', (120,200), cv2.FONT_HERSHEY_SIMPLEX, 1 ,(0,255,0), 4, cv2.LINE_AA)\n",
    "                #cv2.putText(frame, f'Collecting frame {id} for {label}', (15,32), cv2.FONT_HERSHEY_SIMPLEX, 1 ,(0,255,0), 4, cv2.LINE_AA)\n",
    "                cv2.imshow('LIS', frame)\n",
    "                cv2.waitKey(1000)\n",
    "            else:                \n",
    "                data.append(points_detection(results))\n",
    "                cv2.putText(frame, f'Collecting frame {id} for {label}', (15,32), cv2.FONT_HERSHEY_SIMPLEX, 1 ,(0,255,0), 4, cv2.LINE_AA) \n",
    "                cv2.waitKey(100)\n",
    "                cv2.imshow('LIS', frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    100\n",
      "b    100\n",
      "c    100\n",
      "Name: y, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.425902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.340059e-07</td>\n",
       "      <td>0.695783</td>\n",
       "      <td>0.874607</td>\n",
       "      <td>-0.020425</td>\n",
       "      <td>0.901603</td>\n",
       "      <td>0.706403</td>\n",
       "      <td>-0.027040</td>\n",
       "      <td>0.963582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080884</td>\n",
       "      <td>0.412132</td>\n",
       "      <td>-0.021941</td>\n",
       "      <td>0.038354</td>\n",
       "      <td>0.317079</td>\n",
       "      <td>-0.027061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220971</td>\n",
       "      <td>-0.030792</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.390425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.664214e-07</td>\n",
       "      <td>0.658640</td>\n",
       "      <td>0.885224</td>\n",
       "      <td>-0.022115</td>\n",
       "      <td>0.871776</td>\n",
       "      <td>0.730142</td>\n",
       "      <td>-0.030296</td>\n",
       "      <td>0.959132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072933</td>\n",
       "      <td>0.423192</td>\n",
       "      <td>-0.022581</td>\n",
       "      <td>0.034754</td>\n",
       "      <td>0.327254</td>\n",
       "      <td>-0.028437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229601</td>\n",
       "      <td>-0.032413</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.374288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.821520e-07</td>\n",
       "      <td>0.634966</td>\n",
       "      <td>0.894772</td>\n",
       "      <td>-0.021671</td>\n",
       "      <td>0.841212</td>\n",
       "      <td>0.736666</td>\n",
       "      <td>-0.029467</td>\n",
       "      <td>0.930800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.429490</td>\n",
       "      <td>-0.024197</td>\n",
       "      <td>0.024144</td>\n",
       "      <td>0.335471</td>\n",
       "      <td>-0.029346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239120</td>\n",
       "      <td>-0.032613</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.387199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.822724e-07</td>\n",
       "      <td>0.639301</td>\n",
       "      <td>0.889030</td>\n",
       "      <td>-0.022174</td>\n",
       "      <td>0.836478</td>\n",
       "      <td>0.730278</td>\n",
       "      <td>-0.031065</td>\n",
       "      <td>0.921737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065610</td>\n",
       "      <td>0.424691</td>\n",
       "      <td>-0.025182</td>\n",
       "      <td>0.029768</td>\n",
       "      <td>0.332378</td>\n",
       "      <td>-0.030258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238768</td>\n",
       "      <td>-0.033651</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.365346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.105052e-07</td>\n",
       "      <td>0.622440</td>\n",
       "      <td>0.896614</td>\n",
       "      <td>-0.020286</td>\n",
       "      <td>0.829070</td>\n",
       "      <td>0.741293</td>\n",
       "      <td>-0.028262</td>\n",
       "      <td>0.923729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066284</td>\n",
       "      <td>0.426324</td>\n",
       "      <td>-0.026726</td>\n",
       "      <td>0.029319</td>\n",
       "      <td>0.332388</td>\n",
       "      <td>-0.031293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236391</td>\n",
       "      <td>-0.034014</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.361399</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.446333e-07</td>\n",
       "      <td>0.681673</td>\n",
       "      <td>0.900372</td>\n",
       "      <td>-0.022844</td>\n",
       "      <td>0.768471</td>\n",
       "      <td>0.705740</td>\n",
       "      <td>-0.029622</td>\n",
       "      <td>0.502139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558536</td>\n",
       "      <td>-0.041691</td>\n",
       "      <td>0.114536</td>\n",
       "      <td>0.669546</td>\n",
       "      <td>-0.041196</td>\n",
       "      <td>0.176285</td>\n",
       "      <td>0.747251</td>\n",
       "      <td>-0.033475</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.366428</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.880291e-07</td>\n",
       "      <td>0.632464</td>\n",
       "      <td>0.904738</td>\n",
       "      <td>-0.026527</td>\n",
       "      <td>0.702697</td>\n",
       "      <td>0.716121</td>\n",
       "      <td>-0.035356</td>\n",
       "      <td>0.448560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571557</td>\n",
       "      <td>-0.045612</td>\n",
       "      <td>0.106128</td>\n",
       "      <td>0.681197</td>\n",
       "      <td>-0.047473</td>\n",
       "      <td>0.178052</td>\n",
       "      <td>0.747528</td>\n",
       "      <td>-0.041341</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.363903</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.404679e-07</td>\n",
       "      <td>0.655993</td>\n",
       "      <td>0.894866</td>\n",
       "      <td>-0.023968</td>\n",
       "      <td>0.725929</td>\n",
       "      <td>0.700309</td>\n",
       "      <td>-0.030566</td>\n",
       "      <td>0.451680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.557114</td>\n",
       "      <td>-0.043115</td>\n",
       "      <td>0.125017</td>\n",
       "      <td>0.663191</td>\n",
       "      <td>-0.044855</td>\n",
       "      <td>0.220544</td>\n",
       "      <td>0.736120</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.342652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.077550e-07</td>\n",
       "      <td>0.587155</td>\n",
       "      <td>0.884288</td>\n",
       "      <td>-0.023020</td>\n",
       "      <td>0.648971</td>\n",
       "      <td>0.691969</td>\n",
       "      <td>-0.029894</td>\n",
       "      <td>0.410349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552957</td>\n",
       "      <td>-0.041557</td>\n",
       "      <td>0.116282</td>\n",
       "      <td>0.658739</td>\n",
       "      <td>-0.042782</td>\n",
       "      <td>0.208386</td>\n",
       "      <td>0.731682</td>\n",
       "      <td>-0.036044</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.367841</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.297868e-07</td>\n",
       "      <td>0.630628</td>\n",
       "      <td>0.897422</td>\n",
       "      <td>-0.024126</td>\n",
       "      <td>0.697471</td>\n",
       "      <td>0.706715</td>\n",
       "      <td>-0.031748</td>\n",
       "      <td>0.425647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.574309</td>\n",
       "      <td>-0.043767</td>\n",
       "      <td>0.112790</td>\n",
       "      <td>0.685403</td>\n",
       "      <td>-0.045335</td>\n",
       "      <td>0.193438</td>\n",
       "      <td>0.760118</td>\n",
       "      <td>-0.038465</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1             2         3         4         5         6  \\\n",
       "0    0.425902  1.0  1.340059e-07  0.695783  0.874607 -0.020425  0.901603   \n",
       "1    0.390425  1.0  2.664214e-07  0.658640  0.885224 -0.022115  0.871776   \n",
       "2    0.374288  1.0  2.821520e-07  0.634966  0.894772 -0.021671  0.841212   \n",
       "3    0.387199  1.0  2.822724e-07  0.639301  0.889030 -0.022174  0.836478   \n",
       "4    0.365346  1.0  3.105052e-07  0.622440  0.896614 -0.020286  0.829070   \n",
       "..        ...  ...           ...       ...       ...       ...       ...   \n",
       "295  0.361399  1.0  4.446333e-07  0.681673  0.900372 -0.022844  0.768471   \n",
       "296  0.366428  1.0  4.880291e-07  0.632464  0.904738 -0.026527  0.702697   \n",
       "297  0.363903  1.0  4.404679e-07  0.655993  0.894866 -0.023968  0.725929   \n",
       "298  0.342652  1.0  4.077550e-07  0.587155  0.884288 -0.023020  0.648971   \n",
       "299  0.367841  1.0  4.297868e-07  0.630628  0.897422 -0.024126  0.697471   \n",
       "\n",
       "            7         8         9  ...        54        55        56  \\\n",
       "0    0.706403 -0.027040  0.963582  ...  0.080884  0.412132 -0.021941   \n",
       "1    0.730142 -0.030296  0.959132  ...  0.072933  0.423192 -0.022581   \n",
       "2    0.736666 -0.029467  0.930800  ...  0.057700  0.429490 -0.024197   \n",
       "3    0.730278 -0.031065  0.921737  ...  0.065610  0.424691 -0.025182   \n",
       "4    0.741293 -0.028262  0.923729  ...  0.066284  0.426324 -0.026726   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "295  0.705740 -0.029622  0.502139  ...  0.000000  0.558536 -0.041691   \n",
       "296  0.716121 -0.035356  0.448560  ...  0.000000  0.571557 -0.045612   \n",
       "297  0.700309 -0.030566  0.451680  ...  0.000000  0.557114 -0.043115   \n",
       "298  0.691969 -0.029894  0.410349  ...  0.000000  0.552957 -0.041557   \n",
       "299  0.706715 -0.031748  0.425647  ...  0.000000  0.574309 -0.043767   \n",
       "\n",
       "           57        58        59        60        61        62  y  \n",
       "0    0.038354  0.317079 -0.027061  0.000000  0.220971 -0.030792  a  \n",
       "1    0.034754  0.327254 -0.028437  0.000000  0.229601 -0.032413  a  \n",
       "2    0.024144  0.335471 -0.029346  0.000000  0.239120 -0.032613  a  \n",
       "3    0.029768  0.332378 -0.030258  0.000000  0.238768 -0.033651  a  \n",
       "4    0.029319  0.332388 -0.031293  0.000000  0.236391 -0.034014  a  \n",
       "..        ...       ...       ...       ...       ...       ... ..  \n",
       "295  0.114536  0.669546 -0.041196  0.176285  0.747251 -0.033475  c  \n",
       "296  0.106128  0.681197 -0.047473  0.178052  0.747528 -0.041341  c  \n",
       "297  0.125017  0.663191 -0.044855  0.220544  0.736120 -0.038749  c  \n",
       "298  0.116282  0.658739 -0.042782  0.208386  0.731682 -0.036044  c  \n",
       "299  0.112790  0.685403 -0.045335  0.193438  0.760118 -0.038465  c  \n",
       "\n",
       "[300 rows x 64 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(np.array(data))\n",
    "y=[]\n",
    "for i in labels:\n",
    "    y = np.concatenate([y, [i] * (no_sequences-1)])\n",
    "df['y'] = y\n",
    "pd.DataFrame(df).to_csv('data_rh.csv')\n",
    "print(df['y'].value_counts())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, MinMaxScaler\n",
    "import datetime\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0, 'b': 1, 'c': 2}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {label:num for num, label in enumerate(labels)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = np.array(df.iloc[:,0:-1])\n",
    "y = np.array(df.iloc[:,-1])\n",
    "\n",
    "# define min max scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# transform data\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# define LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# transform data\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y = onehot_encoder.fit_transform(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 16:04:24.128162: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2021-11-23 16:04:24.209071: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd01872f2f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-23 16:04:24.209107: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(labels.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/500\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9779 - categorical_accuracy: 0.5625 - val_loss: 0.7931 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/500\n",
      "240/240 [==============================] - 0s 128us/step - loss: 0.6430 - categorical_accuracy: 0.9542 - val_loss: 0.7618 - val_categorical_accuracy: 0.0667\n",
      "Epoch 3/500\n",
      "240/240 [==============================] - 0s 269us/step - loss: 0.3538 - categorical_accuracy: 0.8500 - val_loss: 0.9594 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "240/240 [==============================] - 0s 280us/step - loss: 0.2255 - categorical_accuracy: 0.9167 - val_loss: 0.5931 - val_categorical_accuracy: 0.9000\n",
      "Epoch 5/500\n",
      "240/240 [==============================] - 0s 212us/step - loss: 0.1015 - categorical_accuracy: 1.0000 - val_loss: 0.2037 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "240/240 [==============================] - 0s 270us/step - loss: 0.0276 - categorical_accuracy: 1.0000 - val_loss: 0.0520 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "240/240 [==============================] - 0s 122us/step - loss: 0.0084 - categorical_accuracy: 1.0000 - val_loss: 0.0217 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "240/240 [==============================] - 0s 205us/step - loss: 0.0040 - categorical_accuracy: 1.0000 - val_loss: 0.0145 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "240/240 [==============================] - 0s 207us/step - loss: 0.0025 - categorical_accuracy: 1.0000 - val_loss: 0.0099 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "240/240 [==============================] - 0s 116us/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 0.0079 - val_categorical_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "240/240 [==============================] - 0s 150us/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 0.0070 - val_categorical_accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 0.0061 - val_categorical_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 9.5711e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0052 - val_categorical_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "240/240 [==============================] - 0s 163us/step - loss: 8.1958e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0050 - val_categorical_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "240/240 [==============================] - 0s 146us/step - loss: 7.1212e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0043 - val_categorical_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "240/240 [==============================] - 0s 221us/step - loss: 6.1557e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0039 - val_categorical_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 5.4244e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0036 - val_categorical_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "240/240 [==============================] - 0s 93us/step - loss: 4.8207e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0033 - val_categorical_accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "240/240 [==============================] - 0s 151us/step - loss: 4.3296e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0031 - val_categorical_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "240/240 [==============================] - 0s 128us/step - loss: 3.8871e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0028 - val_categorical_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "240/240 [==============================] - 0s 140us/step - loss: 3.5103e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0025 - val_categorical_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "240/240 [==============================] - 0s 144us/step - loss: 3.2033e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0025 - val_categorical_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "240/240 [==============================] - 0s 203us/step - loss: 2.9160e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0023 - val_categorical_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "240/240 [==============================] - 0s 213us/step - loss: 2.6669e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0021 - val_categorical_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "240/240 [==============================] - 0s 124us/step - loss: 2.4420e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0020 - val_categorical_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 2.2649e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0020 - val_categorical_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 2.0824e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0018 - val_categorical_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "240/240 [==============================] - 0s 84us/step - loss: 1.9472e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0017 - val_categorical_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "240/240 [==============================] - 0s 132us/step - loss: 1.8010e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0017 - val_categorical_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 1.6780e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0016 - val_categorical_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 1.5695e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0015 - val_categorical_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "240/240 [==============================] - 0s 141us/step - loss: 1.4661e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0015 - val_categorical_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "240/240 [==============================] - 0s 133us/step - loss: 1.3775e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0014 - val_categorical_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "240/240 [==============================] - 0s 189us/step - loss: 1.2981e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0013 - val_categorical_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "240/240 [==============================] - 0s 152us/step - loss: 1.2189e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0012 - val_categorical_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "240/240 [==============================] - 0s 153us/step - loss: 1.1567e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0012 - val_categorical_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "240/240 [==============================] - 0s 124us/step - loss: 1.0856e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0012 - val_categorical_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "240/240 [==============================] - 0s 140us/step - loss: 1.0316e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "240/240 [==============================] - 0s 122us/step - loss: 9.7425e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 9.2809e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0010 - val_categorical_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 8.7830e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0010 - val_categorical_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 8.3580e-05 - categorical_accuracy: 1.0000 - val_loss: 9.7580e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "240/240 [==============================] - 0s 116us/step - loss: 7.9953e-05 - categorical_accuracy: 1.0000 - val_loss: 9.2112e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "240/240 [==============================] - 0s 117us/step - loss: 7.5989e-05 - categorical_accuracy: 1.0000 - val_loss: 9.2045e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "240/240 [==============================] - 0s 96us/step - loss: 7.2712e-05 - categorical_accuracy: 1.0000 - val_loss: 8.9305e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 6.9230e-05 - categorical_accuracy: 1.0000 - val_loss: 8.6930e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "240/240 [==============================] - 0s 90us/step - loss: 6.6232e-05 - categorical_accuracy: 1.0000 - val_loss: 8.4088e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 48/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 142us/step - loss: 6.3574e-05 - categorical_accuracy: 1.0000 - val_loss: 8.2271e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "240/240 [==============================] - 0s 167us/step - loss: 6.0784e-05 - categorical_accuracy: 1.0000 - val_loss: 7.9235e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "240/240 [==============================] - 0s 200us/step - loss: 5.8235e-05 - categorical_accuracy: 1.0000 - val_loss: 7.8066e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "240/240 [==============================] - 0s 142us/step - loss: 5.6025e-05 - categorical_accuracy: 1.0000 - val_loss: 7.6693e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "240/240 [==============================] - 0s 206us/step - loss: 5.3654e-05 - categorical_accuracy: 1.0000 - val_loss: 7.2283e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 5.1687e-05 - categorical_accuracy: 1.0000 - val_loss: 7.1320e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "240/240 [==============================] - 0s 99us/step - loss: 4.9830e-05 - categorical_accuracy: 1.0000 - val_loss: 6.6980e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 4.7410e-05 - categorical_accuracy: 1.0000 - val_loss: 6.5540e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 4.5180e-05 - categorical_accuracy: 1.0000 - val_loss: 6.3508e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 4.2920e-05 - categorical_accuracy: 1.0000 - val_loss: 6.1565e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "240/240 [==============================] - 0s 140us/step - loss: 4.0930e-05 - categorical_accuracy: 1.0000 - val_loss: 5.9312e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "240/240 [==============================] - 0s 88us/step - loss: 3.8718e-05 - categorical_accuracy: 1.0000 - val_loss: 5.6047e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "240/240 [==============================] - 0s 119us/step - loss: 3.6622e-05 - categorical_accuracy: 1.0000 - val_loss: 5.1686e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "240/240 [==============================] - 0s 119us/step - loss: 3.4706e-05 - categorical_accuracy: 1.0000 - val_loss: 4.6498e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "240/240 [==============================] - 0s 139us/step - loss: 3.2503e-05 - categorical_accuracy: 1.0000 - val_loss: 4.3831e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "240/240 [==============================] - 0s 140us/step - loss: 3.0647e-05 - categorical_accuracy: 1.0000 - val_loss: 4.1328e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "240/240 [==============================] - 0s 117us/step - loss: 2.8749e-05 - categorical_accuracy: 1.0000 - val_loss: 3.7581e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "240/240 [==============================] - 0s 125us/step - loss: 2.6859e-05 - categorical_accuracy: 1.0000 - val_loss: 3.4820e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "240/240 [==============================] - 0s 154us/step - loss: 2.5321e-05 - categorical_accuracy: 1.0000 - val_loss: 3.0582e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 2.3764e-05 - categorical_accuracy: 1.0000 - val_loss: 2.8815e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "240/240 [==============================] - 0s 141us/step - loss: 2.2310e-05 - categorical_accuracy: 1.0000 - val_loss: 2.6957e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "240/240 [==============================] - 0s 170us/step - loss: 2.1147e-05 - categorical_accuracy: 1.0000 - val_loss: 2.4803e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 1.9928e-05 - categorical_accuracy: 1.0000 - val_loss: 2.2665e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "240/240 [==============================] - 0s 144us/step - loss: 1.8895e-05 - categorical_accuracy: 1.0000 - val_loss: 2.0901e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "240/240 [==============================] - 0s 130us/step - loss: 1.7949e-05 - categorical_accuracy: 1.0000 - val_loss: 1.9407e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "240/240 [==============================] - 0s 136us/step - loss: 1.7114e-05 - categorical_accuracy: 1.0000 - val_loss: 1.8635e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "240/240 [==============================] - 0s 124us/step - loss: 1.6320e-05 - categorical_accuracy: 1.0000 - val_loss: 1.7389e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "240/240 [==============================] - 0s 143us/step - loss: 1.5614e-05 - categorical_accuracy: 1.0000 - val_loss: 1.6052e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 1.4981e-05 - categorical_accuracy: 1.0000 - val_loss: 1.5297e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "240/240 [==============================] - 0s 99us/step - loss: 1.4351e-05 - categorical_accuracy: 1.0000 - val_loss: 1.4590e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "240/240 [==============================] - 0s 117us/step - loss: 1.3774e-05 - categorical_accuracy: 1.0000 - val_loss: 1.3756e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 1.3221e-05 - categorical_accuracy: 1.0000 - val_loss: 1.3251e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "240/240 [==============================] - 0s 93us/step - loss: 1.2734e-05 - categorical_accuracy: 1.0000 - val_loss: 1.2545e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 1.2361e-05 - categorical_accuracy: 1.0000 - val_loss: 1.2277e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "240/240 [==============================] - 0s 95us/step - loss: 1.1863e-05 - categorical_accuracy: 1.0000 - val_loss: 1.1823e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 1.1453e-05 - categorical_accuracy: 1.0000 - val_loss: 1.1098e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "240/240 [==============================] - 0s 119us/step - loss: 1.1068e-05 - categorical_accuracy: 1.0000 - val_loss: 1.0752e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "240/240 [==============================] - 0s 123us/step - loss: 1.0709e-05 - categorical_accuracy: 1.0000 - val_loss: 1.0366e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 1.0367e-05 - categorical_accuracy: 1.0000 - val_loss: 1.0060e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 1.0006e-05 - categorical_accuracy: 1.0000 - val_loss: 9.6378e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "240/240 [==============================] - 0s 88us/step - loss: 9.7031e-06 - categorical_accuracy: 1.0000 - val_loss: 9.2869e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 9.4424e-06 - categorical_accuracy: 1.0000 - val_loss: 8.9983e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "240/240 [==============================] - 0s 94us/step - loss: 9.1498e-06 - categorical_accuracy: 1.0000 - val_loss: 8.8149e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 8.8836e-06 - categorical_accuracy: 1.0000 - val_loss: 8.6202e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "240/240 [==============================] - 0s 122us/step - loss: 8.6184e-06 - categorical_accuracy: 1.0000 - val_loss: 8.2310e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "240/240 [==============================] - 0s 138us/step - loss: 8.3736e-06 - categorical_accuracy: 1.0000 - val_loss: 7.9337e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "240/240 [==============================] - 0s 125us/step - loss: 8.1466e-06 - categorical_accuracy: 1.0000 - val_loss: 7.7043e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "240/240 [==============================] - 0s 119us/step - loss: 7.9380e-06 - categorical_accuracy: 1.0000 - val_loss: 7.5645e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "240/240 [==============================] - 0s 127us/step - loss: 7.7095e-06 - categorical_accuracy: 1.0000 - val_loss: 7.3970e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 7.5218e-06 - categorical_accuracy: 1.0000 - val_loss: 7.2632e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 7.3261e-06 - categorical_accuracy: 1.0000 - val_loss: 7.0105e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "240/240 [==============================] - 0s 185us/step - loss: 7.1249e-06 - categorical_accuracy: 1.0000 - val_loss: 6.8428e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "240/240 [==============================] - 0s 174us/step - loss: 6.9700e-06 - categorical_accuracy: 1.0000 - val_loss: 6.7443e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "240/240 [==============================] - 0s 158us/step - loss: 6.7832e-06 - categorical_accuracy: 1.0000 - val_loss: 6.6260e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "240/240 [==============================] - 0s 163us/step - loss: 6.6253e-06 - categorical_accuracy: 1.0000 - val_loss: 6.3677e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "240/240 [==============================] - 0s 121us/step - loss: 6.4410e-06 - categorical_accuracy: 1.0000 - val_loss: 6.2560e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "240/240 [==============================] - 0s 127us/step - loss: 6.3149e-06 - categorical_accuracy: 1.0000 - val_loss: 6.1517e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "240/240 [==============================] - 0s 99us/step - loss: 6.1425e-06 - categorical_accuracy: 1.0000 - val_loss: 5.9701e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 6.0238e-06 - categorical_accuracy: 1.0000 - val_loss: 5.8800e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "240/240 [==============================] - 0s 117us/step - loss: 5.8872e-06 - categorical_accuracy: 1.0000 - val_loss: 5.8305e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "240/240 [==============================] - 0s 116us/step - loss: 5.7536e-06 - categorical_accuracy: 1.0000 - val_loss: 5.6638e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "240/240 [==============================] - 0s 146us/step - loss: 5.6305e-06 - categorical_accuracy: 1.0000 - val_loss: 5.5770e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "240/240 [==============================] - 0s 198us/step - loss: 5.4914e-06 - categorical_accuracy: 1.0000 - val_loss: 5.4035e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "240/240 [==============================] - 0s 98us/step - loss: 5.3796e-06 - categorical_accuracy: 1.0000 - val_loss: 5.3439e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 5.2500e-06 - categorical_accuracy: 1.0000 - val_loss: 5.2355e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 5.1467e-06 - categorical_accuracy: 1.0000 - val_loss: 5.1450e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "240/240 [==============================] - 0s 123us/step - loss: 5.0409e-06 - categorical_accuracy: 1.0000 - val_loss: 5.0437e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "240/240 [==============================] - 0s 148us/step - loss: 4.9356e-06 - categorical_accuracy: 1.0000 - val_loss: 5.0360e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "240/240 [==============================] - 0s 116us/step - loss: 4.8293e-06 - categorical_accuracy: 1.0000 - val_loss: 4.9260e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "240/240 [==============================] - 0s 89us/step - loss: 4.7200e-06 - categorical_accuracy: 1.0000 - val_loss: 4.8327e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "240/240 [==============================] - 0s 129us/step - loss: 4.6421e-06 - categorical_accuracy: 1.0000 - val_loss: 4.7324e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "240/240 [==============================] - 0s 125us/step - loss: 4.5343e-06 - categorical_accuracy: 1.0000 - val_loss: 4.6687e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "240/240 [==============================] - 0s 246us/step - loss: 4.4459e-06 - categorical_accuracy: 1.0000 - val_loss: 4.6363e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 4.3729e-06 - categorical_accuracy: 1.0000 - val_loss: 4.6006e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "240/240 [==============================] - 0s 94us/step - loss: 4.2725e-06 - categorical_accuracy: 1.0000 - val_loss: 4.4987e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 4.1965e-06 - categorical_accuracy: 1.0000 - val_loss: 4.4032e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "240/240 [==============================] - 0s 122us/step - loss: 4.1116e-06 - categorical_accuracy: 1.0000 - val_loss: 4.3683e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "240/240 [==============================] - 0s 122us/step - loss: 4.0416e-06 - categorical_accuracy: 1.0000 - val_loss: 4.2797e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "240/240 [==============================] - 0s 157us/step - loss: 3.9661e-06 - categorical_accuracy: 1.0000 - val_loss: 4.2027e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 3.8826e-06 - categorical_accuracy: 1.0000 - val_loss: 4.1429e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 3.8161e-06 - categorical_accuracy: 1.0000 - val_loss: 4.0764e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "240/240 [==============================] - 0s 386us/step - loss: 3.7540e-06 - categorical_accuracy: 1.0000 - val_loss: 4.0569e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 3.6755e-06 - categorical_accuracy: 1.0000 - val_loss: 3.9856e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "240/240 [==============================] - 0s 89us/step - loss: 3.6025e-06 - categorical_accuracy: 1.0000 - val_loss: 3.9289e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "240/240 [==============================] - 0s 79us/step - loss: 3.5379e-06 - categorical_accuracy: 1.0000 - val_loss: 3.8754e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "240/240 [==============================] - 0s 88us/step - loss: 3.4838e-06 - categorical_accuracy: 1.0000 - val_loss: 3.8592e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "240/240 [==============================] - 0s 116us/step - loss: 3.4192e-06 - categorical_accuracy: 1.0000 - val_loss: 3.8157e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "240/240 [==============================] - 0s 117us/step - loss: 3.3621e-06 - categorical_accuracy: 1.0000 - val_loss: 3.7476e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "240/240 [==============================] - 0s 138us/step - loss: 3.3020e-06 - categorical_accuracy: 1.0000 - val_loss: 3.6876e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "240/240 [==============================] - 0s 155us/step - loss: 3.2444e-06 - categorical_accuracy: 1.0000 - val_loss: 3.6233e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "240/240 [==============================] - 0s 291us/step - loss: 3.1823e-06 - categorical_accuracy: 1.0000 - val_loss: 3.5901e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "240/240 [==============================] - 0s 91us/step - loss: 3.1277e-06 - categorical_accuracy: 1.0000 - val_loss: 3.5522e-05 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/500\n",
      "240/240 [==============================] - 0s 74us/step - loss: 3.0755e-06 - categorical_accuracy: 1.0000 - val_loss: 3.5299e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "240/240 [==============================] - 0s 78us/step - loss: 3.0239e-06 - categorical_accuracy: 1.0000 - val_loss: 3.4821e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "240/240 [==============================] - 0s 76us/step - loss: 2.9683e-06 - categorical_accuracy: 1.0000 - val_loss: 3.4578e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "240/240 [==============================] - 0s 96us/step - loss: 2.9206e-06 - categorical_accuracy: 1.0000 - val_loss: 3.4062e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 2.8744e-06 - categorical_accuracy: 1.0000 - val_loss: 3.3820e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "240/240 [==============================] - 0s 124us/step - loss: 2.8391e-06 - categorical_accuracy: 1.0000 - val_loss: 3.3645e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "240/240 [==============================] - 0s 118us/step - loss: 2.7870e-06 - categorical_accuracy: 1.0000 - val_loss: 3.3309e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "240/240 [==============================] - 0s 165us/step - loss: 2.7298e-06 - categorical_accuracy: 1.0000 - val_loss: 3.2882e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "240/240 [==============================] - 0s 341us/step - loss: 2.6921e-06 - categorical_accuracy: 1.0000 - val_loss: 3.2660e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "240/240 [==============================] - 0s 145us/step - loss: 2.6484e-06 - categorical_accuracy: 1.0000 - val_loss: 3.2189e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "240/240 [==============================] - 0s 91us/step - loss: 2.6062e-06 - categorical_accuracy: 1.0000 - val_loss: 3.1618e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "240/240 [==============================] - 0s 87us/step - loss: 2.5704e-06 - categorical_accuracy: 1.0000 - val_loss: 3.1461e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "240/240 [==============================] - 0s 125us/step - loss: 2.5322e-06 - categorical_accuracy: 1.0000 - val_loss: 3.1179e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "240/240 [==============================] - 0s 132us/step - loss: 2.4845e-06 - categorical_accuracy: 1.0000 - val_loss: 3.1131e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "240/240 [==============================] - 0s 126us/step - loss: 2.4487e-06 - categorical_accuracy: 1.0000 - val_loss: 3.0771e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "240/240 [==============================] - 0s 149us/step - loss: 2.4090e-06 - categorical_accuracy: 1.0000 - val_loss: 3.0360e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "240/240 [==============================] - 0s 94us/step - loss: 2.3782e-06 - categorical_accuracy: 1.0000 - val_loss: 3.0019e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "240/240 [==============================] - 0s 146us/step - loss: 2.3340e-06 - categorical_accuracy: 1.0000 - val_loss: 2.9951e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 2.3007e-06 - categorical_accuracy: 1.0000 - val_loss: 2.9491e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "240/240 [==============================] - 0s 97us/step - loss: 2.2644e-06 - categorical_accuracy: 1.0000 - val_loss: 2.9175e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 2.2287e-06 - categorical_accuracy: 1.0000 - val_loss: 2.8940e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 2.1989e-06 - categorical_accuracy: 1.0000 - val_loss: 2.8692e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 2.1691e-06 - categorical_accuracy: 1.0000 - val_loss: 2.8597e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "240/240 [==============================] - 0s 116us/step - loss: 2.1353e-06 - categorical_accuracy: 1.0000 - val_loss: 2.8184e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "240/240 [==============================] - 0s 80us/step - loss: 2.1050e-06 - categorical_accuracy: 1.0000 - val_loss: 2.7981e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "240/240 [==============================] - 0s 87us/step - loss: 2.0683e-06 - categorical_accuracy: 1.0000 - val_loss: 2.7695e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "240/240 [==============================] - 0s 81us/step - loss: 2.0424e-06 - categorical_accuracy: 1.0000 - val_loss: 2.7427e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "240/240 [==============================] - 0s 81us/step - loss: 2.0091e-06 - categorical_accuracy: 1.0000 - val_loss: 2.7497e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "240/240 [==============================] - 0s 80us/step - loss: 1.9808e-06 - categorical_accuracy: 1.0000 - val_loss: 2.7191e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "240/240 [==============================] - 0s 134us/step - loss: 1.9545e-06 - categorical_accuracy: 1.0000 - val_loss: 2.6720e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "240/240 [==============================] - 0s 131us/step - loss: 1.9252e-06 - categorical_accuracy: 1.0000 - val_loss: 2.6355e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "240/240 [==============================] - 0s 117us/step - loss: 1.8994e-06 - categorical_accuracy: 1.0000 - val_loss: 2.6116e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 1.8686e-06 - categorical_accuracy: 1.0000 - val_loss: 2.5827e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 1.8457e-06 - categorical_accuracy: 1.0000 - val_loss: 2.5634e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "240/240 [==============================] - 0s 438us/step - loss: 1.8274e-06 - categorical_accuracy: 1.0000 - val_loss: 2.5550e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 1.8035e-06 - categorical_accuracy: 1.0000 - val_loss: 2.5264e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 1.7777e-06 - categorical_accuracy: 1.0000 - val_loss: 2.4998e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "240/240 [==============================] - 0s 95us/step - loss: 1.7489e-06 - categorical_accuracy: 1.0000 - val_loss: 2.4641e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "240/240 [==============================] - 0s 160us/step - loss: 1.7260e-06 - categorical_accuracy: 1.0000 - val_loss: 2.4569e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "240/240 [==============================] - 0s 215us/step - loss: 1.7027e-06 - categorical_accuracy: 1.0000 - val_loss: 2.4321e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "240/240 [==============================] - 0s 82us/step - loss: 1.6828e-06 - categorical_accuracy: 1.0000 - val_loss: 2.4174e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "240/240 [==============================] - 0s 80us/step - loss: 1.6610e-06 - categorical_accuracy: 1.0000 - val_loss: 2.3926e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "240/240 [==============================] - 0s 81us/step - loss: 1.6376e-06 - categorical_accuracy: 1.0000 - val_loss: 2.3711e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "240/240 [==============================] - 0s 91us/step - loss: 1.6143e-06 - categorical_accuracy: 1.0000 - val_loss: 2.3342e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "240/240 [==============================] - 0s 142us/step - loss: 1.5924e-06 - categorical_accuracy: 1.0000 - val_loss: 2.3239e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "240/240 [==============================] - 0s 269us/step - loss: 1.5750e-06 - categorical_accuracy: 1.0000 - val_loss: 2.2998e-05 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 1.5596e-06 - categorical_accuracy: 1.0000 - val_loss: 2.3002e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "240/240 [==============================] - 0s 133us/step - loss: 1.5368e-06 - categorical_accuracy: 1.0000 - val_loss: 2.2816e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 1.5115e-06 - categorical_accuracy: 1.0000 - val_loss: 2.2462e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "240/240 [==============================] - 0s 123us/step - loss: 1.4906e-06 - categorical_accuracy: 1.0000 - val_loss: 2.2319e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "240/240 [==============================] - 0s 133us/step - loss: 1.4727e-06 - categorical_accuracy: 1.0000 - val_loss: 2.2146e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "240/240 [==============================] - 0s 154us/step - loss: 1.4533e-06 - categorical_accuracy: 1.0000 - val_loss: 2.1926e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 1.4360e-06 - categorical_accuracy: 1.0000 - val_loss: 2.1690e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "240/240 [==============================] - 0s 121us/step - loss: 1.4191e-06 - categorical_accuracy: 1.0000 - val_loss: 2.1572e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "240/240 [==============================] - 0s 119us/step - loss: 1.3997e-06 - categorical_accuracy: 1.0000 - val_loss: 2.1342e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 1.3853e-06 - categorical_accuracy: 1.0000 - val_loss: 2.1298e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 1.3639e-06 - categorical_accuracy: 1.0000 - val_loss: 2.1213e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "240/240 [==============================] - 0s 154us/step - loss: 1.3441e-06 - categorical_accuracy: 1.0000 - val_loss: 2.1050e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "240/240 [==============================] - 0s 150us/step - loss: 1.3272e-06 - categorical_accuracy: 1.0000 - val_loss: 2.0836e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "240/240 [==============================] - 0s 123us/step - loss: 1.3098e-06 - categorical_accuracy: 1.0000 - val_loss: 2.0562e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "240/240 [==============================] - 0s 119us/step - loss: 1.2929e-06 - categorical_accuracy: 1.0000 - val_loss: 2.0524e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "240/240 [==============================] - 0s 131us/step - loss: 1.2785e-06 - categorical_accuracy: 1.0000 - val_loss: 2.0452e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "240/240 [==============================] - 0s 232us/step - loss: 1.2656e-06 - categorical_accuracy: 1.0000 - val_loss: 2.0264e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "240/240 [==============================] - 0s 335us/step - loss: 1.2552e-06 - categorical_accuracy: 1.0000 - val_loss: 2.0184e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "240/240 [==============================] - 0s 148us/step - loss: 1.2353e-06 - categorical_accuracy: 1.0000 - val_loss: 1.9950e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "240/240 [==============================] - 0s 256us/step - loss: 1.2234e-06 - categorical_accuracy: 1.0000 - val_loss: 1.9751e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "240/240 [==============================] - 0s 258us/step - loss: 1.2070e-06 - categorical_accuracy: 1.0000 - val_loss: 1.9588e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "240/240 [==============================] - 0s 158us/step - loss: 1.1941e-06 - categorical_accuracy: 1.0000 - val_loss: 1.9560e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "240/240 [==============================] - 0s 176us/step - loss: 1.1812e-06 - categorical_accuracy: 1.0000 - val_loss: 1.9350e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "240/240 [==============================] - 0s 260us/step - loss: 1.1638e-06 - categorical_accuracy: 1.0000 - val_loss: 1.9225e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "240/240 [==============================] - 0s 254us/step - loss: 1.1528e-06 - categorical_accuracy: 1.0000 - val_loss: 1.9092e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "240/240 [==============================] - 0s 205us/step - loss: 1.1325e-06 - categorical_accuracy: 1.0000 - val_loss: 1.8994e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "240/240 [==============================] - 0s 198us/step - loss: 1.1191e-06 - categorical_accuracy: 1.0000 - val_loss: 1.8915e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "240/240 [==============================] - 0s 224us/step - loss: 1.1101e-06 - categorical_accuracy: 1.0000 - val_loss: 1.8780e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "240/240 [==============================] - 0s 185us/step - loss: 1.0927e-06 - categorical_accuracy: 1.0000 - val_loss: 1.8567e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 1.0828e-06 - categorical_accuracy: 1.0000 - val_loss: 1.8500e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "240/240 [==============================] - 0s 139us/step - loss: 1.0679e-06 - categorical_accuracy: 1.0000 - val_loss: 1.8430e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "240/240 [==============================] - 0s 123us/step - loss: 1.0560e-06 - categorical_accuracy: 1.0000 - val_loss: 1.8337e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "240/240 [==============================] - 0s 132us/step - loss: 1.0441e-06 - categorical_accuracy: 1.0000 - val_loss: 1.8192e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "240/240 [==============================] - 0s 94us/step - loss: 1.0331e-06 - categorical_accuracy: 1.0000 - val_loss: 1.8117e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "240/240 [==============================] - 0s 78us/step - loss: 1.0247e-06 - categorical_accuracy: 1.0000 - val_loss: 1.8059e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "240/240 [==============================] - 0s 122us/step - loss: 1.0103e-06 - categorical_accuracy: 1.0000 - val_loss: 1.7932e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 9.9738e-07 - categorical_accuracy: 1.0000 - val_loss: 1.7795e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "240/240 [==============================] - 0s 158us/step - loss: 9.8446e-07 - categorical_accuracy: 1.0000 - val_loss: 1.7668e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "240/240 [==============================] - 0s 93us/step - loss: 9.7254e-07 - categorical_accuracy: 1.0000 - val_loss: 1.7578e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "240/240 [==============================] - 0s 176us/step - loss: 9.6658e-07 - categorical_accuracy: 1.0000 - val_loss: 1.7535e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "240/240 [==============================] - 0s 124us/step - loss: 9.5168e-07 - categorical_accuracy: 1.0000 - val_loss: 1.7332e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "240/240 [==============================] - 0s 123us/step - loss: 9.4423e-07 - categorical_accuracy: 1.0000 - val_loss: 1.7233e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 9.3132e-07 - categorical_accuracy: 1.0000 - val_loss: 1.7137e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 9.2188e-07 - categorical_accuracy: 1.0000 - val_loss: 1.7100e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "240/240 [==============================] - 0s 144us/step - loss: 9.1641e-07 - categorical_accuracy: 1.0000 - val_loss: 1.7000e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "240/240 [==============================] - 0s 158us/step - loss: 9.0499e-07 - categorical_accuracy: 1.0000 - val_loss: 1.6859e-05 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/500\n",
      "240/240 [==============================] - 0s 149us/step - loss: 8.9704e-07 - categorical_accuracy: 1.0000 - val_loss: 1.6798e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "240/240 [==============================] - 0s 184us/step - loss: 8.8661e-07 - categorical_accuracy: 1.0000 - val_loss: 1.6673e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "240/240 [==============================] - 0s 121us/step - loss: 8.7469e-07 - categorical_accuracy: 1.0000 - val_loss: 1.6541e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "240/240 [==============================] - 0s 116us/step - loss: 8.6625e-07 - categorical_accuracy: 1.0000 - val_loss: 1.6534e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 8.5929e-07 - categorical_accuracy: 1.0000 - val_loss: 1.6400e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 8.4986e-07 - categorical_accuracy: 1.0000 - val_loss: 1.6267e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 8.3843e-07 - categorical_accuracy: 1.0000 - val_loss: 1.6116e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "240/240 [==============================] - 0s 123us/step - loss: 8.2800e-07 - categorical_accuracy: 1.0000 - val_loss: 1.6035e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 8.2055e-07 - categorical_accuracy: 1.0000 - val_loss: 1.6033e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "240/240 [==============================] - 0s 152us/step - loss: 8.0813e-07 - categorical_accuracy: 1.0000 - val_loss: 1.5862e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "240/240 [==============================] - 0s 218us/step - loss: 7.9870e-07 - categorical_accuracy: 1.0000 - val_loss: 1.5880e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "240/240 [==============================] - 0s 228us/step - loss: 7.9025e-07 - categorical_accuracy: 1.0000 - val_loss: 1.5695e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "240/240 [==============================] - 0s 151us/step - loss: 7.8231e-07 - categorical_accuracy: 1.0000 - val_loss: 1.5642e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "240/240 [==============================] - 0s 192us/step - loss: 7.7585e-07 - categorical_accuracy: 1.0000 - val_loss: 1.5574e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "240/240 [==============================] - 0s 144us/step - loss: 7.6492e-07 - categorical_accuracy: 1.0000 - val_loss: 1.5517e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 7.5697e-07 - categorical_accuracy: 1.0000 - val_loss: 1.5336e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 7.4704e-07 - categorical_accuracy: 1.0000 - val_loss: 1.5244e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "240/240 [==============================] - 0s 150us/step - loss: 7.4058e-07 - categorical_accuracy: 1.0000 - val_loss: 1.5163e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 7.3611e-07 - categorical_accuracy: 1.0000 - val_loss: 1.5082e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 7.2966e-07 - categorical_accuracy: 1.0000 - val_loss: 1.5022e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "240/240 [==============================] - 0s 94us/step - loss: 7.2121e-07 - categorical_accuracy: 1.0000 - val_loss: 1.4877e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "240/240 [==============================] - 0s 133us/step - loss: 7.1525e-07 - categorical_accuracy: 1.0000 - val_loss: 1.4833e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "240/240 [==============================] - 0s 166us/step - loss: 7.0830e-07 - categorical_accuracy: 1.0000 - val_loss: 1.4730e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 7.0283e-07 - categorical_accuracy: 1.0000 - val_loss: 1.4696e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "240/240 [==============================] - 0s 127us/step - loss: 6.9538e-07 - categorical_accuracy: 1.0000 - val_loss: 1.4571e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 6.8744e-07 - categorical_accuracy: 1.0000 - val_loss: 1.4478e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 6.8148e-07 - categorical_accuracy: 1.0000 - val_loss: 1.4392e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 6.7104e-07 - categorical_accuracy: 1.0000 - val_loss: 1.4323e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "240/240 [==============================] - 0s 146us/step - loss: 6.6608e-07 - categorical_accuracy: 1.0000 - val_loss: 1.4224e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "240/240 [==============================] - 0s 102us/step - loss: 6.5565e-07 - categorical_accuracy: 1.0000 - val_loss: 1.4138e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "240/240 [==============================] - 0s 121us/step - loss: 6.4969e-07 - categorical_accuracy: 1.0000 - val_loss: 1.4027e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "240/240 [==============================] - 0s 86us/step - loss: 6.4273e-07 - categorical_accuracy: 1.0000 - val_loss: 1.4015e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "240/240 [==============================] - 0s 166us/step - loss: 6.3479e-07 - categorical_accuracy: 1.0000 - val_loss: 1.3910e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "240/240 [==============================] - 0s 91us/step - loss: 6.2932e-07 - categorical_accuracy: 1.0000 - val_loss: 1.3892e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "240/240 [==============================] - 0s 132us/step - loss: 6.2237e-07 - categorical_accuracy: 1.0000 - val_loss: 1.3785e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "240/240 [==============================] - 0s 137us/step - loss: 6.1740e-07 - categorical_accuracy: 1.0000 - val_loss: 1.3677e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "240/240 [==============================] - 0s 138us/step - loss: 6.1144e-07 - categorical_accuracy: 1.0000 - val_loss: 1.3697e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "240/240 [==============================] - 0s 126us/step - loss: 6.0349e-07 - categorical_accuracy: 1.0000 - val_loss: 1.3626e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "240/240 [==============================] - 0s 208us/step - loss: 5.9803e-07 - categorical_accuracy: 1.0000 - val_loss: 1.3574e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "240/240 [==============================] - 0s 334us/step - loss: 5.9356e-07 - categorical_accuracy: 1.0000 - val_loss: 1.3512e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "240/240 [==============================] - 0s 247us/step - loss: 5.8859e-07 - categorical_accuracy: 1.0000 - val_loss: 1.3355e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 5.8462e-07 - categorical_accuracy: 1.0000 - val_loss: 1.3256e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "240/240 [==============================] - 0s 80us/step - loss: 5.7866e-07 - categorical_accuracy: 1.0000 - val_loss: 1.3336e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "240/240 [==============================] - 0s 121us/step - loss: 5.7220e-07 - categorical_accuracy: 1.0000 - val_loss: 1.3252e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "240/240 [==============================] - 0s 181us/step - loss: 5.6574e-07 - categorical_accuracy: 1.0000 - val_loss: 1.3179e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "240/240 [==============================] - 0s 184us/step - loss: 5.6028e-07 - categorical_accuracy: 1.0000 - val_loss: 1.3101e-05 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/500\n",
      "240/240 [==============================] - 0s 130us/step - loss: 5.5233e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2994e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "240/240 [==============================] - 0s 122us/step - loss: 5.4687e-07 - categorical_accuracy: 1.0000 - val_loss: 1.3002e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "240/240 [==============================] - 0s 124us/step - loss: 5.3992e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2926e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "240/240 [==============================] - 0s 128us/step - loss: 5.3445e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2827e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "240/240 [==============================] - 0s 145us/step - loss: 5.2899e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2774e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "240/240 [==============================] - 0s 137us/step - loss: 5.2253e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2744e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "240/240 [==============================] - 0s 130us/step - loss: 5.2005e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2716e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "240/240 [==============================] - 0s 117us/step - loss: 5.1806e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2632e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "240/240 [==============================] - 0s 125us/step - loss: 5.1111e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2495e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 5.0316e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2505e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "240/240 [==============================] - 0s 130us/step - loss: 4.9720e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2466e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "240/240 [==============================] - 0s 124us/step - loss: 4.9273e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2382e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "240/240 [==============================] - 0s 129us/step - loss: 4.8776e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2354e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "240/240 [==============================] - 0s 174us/step - loss: 4.8329e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2315e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 4.7783e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2245e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "240/240 [==============================] - 0s 141us/step - loss: 4.7336e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2257e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "240/240 [==============================] - 0s 142us/step - loss: 4.6938e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2180e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "240/240 [==============================] - 0s 173us/step - loss: 4.6392e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2128e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 4.5895e-07 - categorical_accuracy: 1.0000 - val_loss: 1.2134e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "240/240 [==============================] - 0s 124us/step - loss: 4.5697e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1945e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "240/240 [==============================] - 0s 99us/step - loss: 4.5399e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1961e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "240/240 [==============================] - 0s 98us/step - loss: 4.5051e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1909e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "240/240 [==============================] - 0s 161us/step - loss: 4.4405e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1832e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "240/240 [==============================] - 0s 124us/step - loss: 4.3909e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1770e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "240/240 [==============================] - 0s 126us/step - loss: 4.3710e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1687e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "240/240 [==============================] - 0s 126us/step - loss: 4.3213e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1663e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "240/240 [==============================] - 0s 132us/step - loss: 4.2816e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1639e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "240/240 [==============================] - 0s 119us/step - loss: 4.2468e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1576e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "240/240 [==============================] - 0s 119us/step - loss: 4.2170e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1536e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "240/240 [==============================] - 0s 134us/step - loss: 4.1822e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1504e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "240/240 [==============================] - 0s 141us/step - loss: 4.1524e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1409e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "240/240 [==============================] - 0s 167us/step - loss: 4.1028e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1357e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "240/240 [==============================] - 0s 157us/step - loss: 4.0779e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1288e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "240/240 [==============================] - 0s 144us/step - loss: 4.0432e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1260e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "240/240 [==============================] - 0s 121us/step - loss: 4.0233e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1194e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "240/240 [==============================] - 0s 212us/step - loss: 3.9786e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1091e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "240/240 [==============================] - 0s 159us/step - loss: 3.9637e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1093e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "240/240 [==============================] - 0s 178us/step - loss: 3.9091e-07 - categorical_accuracy: 1.0000 - val_loss: 1.1051e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "240/240 [==============================] - 0s 202us/step - loss: 3.8693e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0928e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "240/240 [==============================] - 0s 199us/step - loss: 3.8495e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0879e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "240/240 [==============================] - 0s 138us/step - loss: 3.8196e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0803e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "240/240 [==============================] - 0s 199us/step - loss: 3.7749e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0787e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "240/240 [==============================] - 0s 172us/step - loss: 3.7451e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0734e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "240/240 [==============================] - 0s 139us/step - loss: 3.6955e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0606e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "240/240 [==============================] - 0s 147us/step - loss: 3.6557e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0648e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 3.6259e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0561e-05 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324/500\n",
      "240/240 [==============================] - 0s 169us/step - loss: 3.5812e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0545e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "240/240 [==============================] - 0s 247us/step - loss: 3.5365e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0479e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "240/240 [==============================] - 0s 163us/step - loss: 3.4918e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0426e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "240/240 [==============================] - 0s 147us/step - loss: 3.4471e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0485e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "240/240 [==============================] - 0s 169us/step - loss: 3.4173e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0501e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "240/240 [==============================] - 0s 175us/step - loss: 3.3776e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0420e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "240/240 [==============================] - 0s 154us/step - loss: 3.3527e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0414e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "240/240 [==============================] - 0s 176us/step - loss: 3.3080e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0342e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "240/240 [==============================] - 0s 116us/step - loss: 3.2931e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0330e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "240/240 [==============================] - 0s 129us/step - loss: 3.2683e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0308e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 3.2484e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0241e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "240/240 [==============================] - 0s 132us/step - loss: 3.2037e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0199e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 3.1789e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0205e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "240/240 [==============================] - 0s 97us/step - loss: 3.1590e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0163e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "240/240 [==============================] - 0s 132us/step - loss: 3.1243e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0136e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "240/240 [==============================] - 0s 116us/step - loss: 3.1044e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0106e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "240/240 [==============================] - 0s 119us/step - loss: 3.0647e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0050e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "240/240 [==============================] - 0s 126us/step - loss: 3.0349e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0024e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 2.9852e-07 - categorical_accuracy: 1.0000 - val_loss: 1.0014e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "240/240 [==============================] - 0s 118us/step - loss: 2.9653e-07 - categorical_accuracy: 1.0000 - val_loss: 9.9926e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "240/240 [==============================] - 0s 126us/step - loss: 2.9405e-07 - categorical_accuracy: 1.0000 - val_loss: 9.9230e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "240/240 [==============================] - 0s 136us/step - loss: 2.9206e-07 - categorical_accuracy: 1.0000 - val_loss: 9.8913e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "240/240 [==============================] - 0s 161us/step - loss: 2.9008e-07 - categorical_accuracy: 1.0000 - val_loss: 9.8674e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "240/240 [==============================] - 0s 153us/step - loss: 2.8759e-07 - categorical_accuracy: 1.0000 - val_loss: 9.8972e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "240/240 [==============================] - 0s 133us/step - loss: 2.8511e-07 - categorical_accuracy: 1.0000 - val_loss: 9.8039e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "240/240 [==============================] - 0s 125us/step - loss: 2.8213e-07 - categorical_accuracy: 1.0000 - val_loss: 9.7661e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "240/240 [==============================] - 0s 139us/step - loss: 2.8064e-07 - categorical_accuracy: 1.0000 - val_loss: 9.7661e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "240/240 [==============================] - 0s 175us/step - loss: 2.7716e-07 - categorical_accuracy: 1.0000 - val_loss: 9.7085e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "240/240 [==============================] - 0s 133us/step - loss: 2.7567e-07 - categorical_accuracy: 1.0000 - val_loss: 9.6012e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "240/240 [==============================] - 0s 126us/step - loss: 2.7269e-07 - categorical_accuracy: 1.0000 - val_loss: 9.6290e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "240/240 [==============================] - 0s 142us/step - loss: 2.7070e-07 - categorical_accuracy: 1.0000 - val_loss: 9.6052e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "240/240 [==============================] - 0s 293us/step - loss: 2.6822e-07 - categorical_accuracy: 1.0000 - val_loss: 9.5198e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "240/240 [==============================] - 0s 157us/step - loss: 2.6673e-07 - categorical_accuracy: 1.0000 - val_loss: 9.4920e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "240/240 [==============================] - 0s 164us/step - loss: 2.6474e-07 - categorical_accuracy: 1.0000 - val_loss: 9.4006e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "240/240 [==============================] - 0s 180us/step - loss: 2.6176e-07 - categorical_accuracy: 1.0000 - val_loss: 9.3927e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "240/240 [==============================] - 0s 188us/step - loss: 2.5978e-07 - categorical_accuracy: 1.0000 - val_loss: 9.3629e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "240/240 [==============================] - 0s 205us/step - loss: 2.5680e-07 - categorical_accuracy: 1.0000 - val_loss: 9.3092e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "240/240 [==============================] - 0s 210us/step - loss: 2.5382e-07 - categorical_accuracy: 1.0000 - val_loss: 9.2576e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "240/240 [==============================] - 0s 178us/step - loss: 2.5233e-07 - categorical_accuracy: 1.0000 - val_loss: 9.2298e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "240/240 [==============================] - 0s 170us/step - loss: 2.5034e-07 - categorical_accuracy: 1.0000 - val_loss: 9.1702e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 2.4885e-07 - categorical_accuracy: 1.0000 - val_loss: 9.1364e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "240/240 [==============================] - 0s 133us/step - loss: 2.4686e-07 - categorical_accuracy: 1.0000 - val_loss: 9.0669e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "240/240 [==============================] - 0s 125us/step - loss: 2.4537e-07 - categorical_accuracy: 1.0000 - val_loss: 8.9854e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "240/240 [==============================] - 0s 116us/step - loss: 2.4090e-07 - categorical_accuracy: 1.0000 - val_loss: 8.9735e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 2.3891e-07 - categorical_accuracy: 1.0000 - val_loss: 8.9398e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 2.3544e-07 - categorical_accuracy: 1.0000 - val_loss: 8.9080e-06 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 2.3196e-07 - categorical_accuracy: 1.0000 - val_loss: 8.8067e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 2.2898e-07 - categorical_accuracy: 1.0000 - val_loss: 8.7530e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "240/240 [==============================] - 0s 129us/step - loss: 2.2799e-07 - categorical_accuracy: 1.0000 - val_loss: 8.7610e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "240/240 [==============================] - 0s 121us/step - loss: 2.2600e-07 - categorical_accuracy: 1.0000 - val_loss: 8.7312e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 2.2302e-07 - categorical_accuracy: 1.0000 - val_loss: 8.6100e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "240/240 [==============================] - 0s 126us/step - loss: 2.2203e-07 - categorical_accuracy: 1.0000 - val_loss: 8.5464e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "240/240 [==============================] - 0s 190us/step - loss: 2.2103e-07 - categorical_accuracy: 1.0000 - val_loss: 8.5166e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 2.1805e-07 - categorical_accuracy: 1.0000 - val_loss: 8.4630e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "240/240 [==============================] - 0s 146us/step - loss: 2.1656e-07 - categorical_accuracy: 1.0000 - val_loss: 8.4292e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "240/240 [==============================] - 0s 100us/step - loss: 2.1408e-07 - categorical_accuracy: 1.0000 - val_loss: 8.3836e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "240/240 [==============================] - 0s 119us/step - loss: 2.1259e-07 - categorical_accuracy: 1.0000 - val_loss: 8.3716e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "240/240 [==============================] - 0s 140us/step - loss: 2.1209e-07 - categorical_accuracy: 1.0000 - val_loss: 8.3240e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "240/240 [==============================] - 0s 215us/step - loss: 2.0911e-07 - categorical_accuracy: 1.0000 - val_loss: 8.2822e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "240/240 [==============================] - 0s 127us/step - loss: 2.0713e-07 - categorical_accuracy: 1.0000 - val_loss: 8.2604e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "240/240 [==============================] - 0s 293us/step - loss: 2.0365e-07 - categorical_accuracy: 1.0000 - val_loss: 8.1929e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "240/240 [==============================] - 0s 194us/step - loss: 2.0365e-07 - categorical_accuracy: 1.0000 - val_loss: 8.1591e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "240/240 [==============================] - 0s 255us/step - loss: 2.0216e-07 - categorical_accuracy: 1.0000 - val_loss: 8.1055e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "240/240 [==============================] - 0s 136us/step - loss: 2.0017e-07 - categorical_accuracy: 1.0000 - val_loss: 8.1055e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "240/240 [==============================] - 0s 125us/step - loss: 1.9968e-07 - categorical_accuracy: 1.0000 - val_loss: 8.0260e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "240/240 [==============================] - 0s 215us/step - loss: 1.9818e-07 - categorical_accuracy: 1.0000 - val_loss: 7.9465e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "240/240 [==============================] - 0s 193us/step - loss: 1.9620e-07 - categorical_accuracy: 1.0000 - val_loss: 7.9485e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "240/240 [==============================] - 0s 131us/step - loss: 1.9520e-07 - categorical_accuracy: 1.0000 - val_loss: 7.9167e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "240/240 [==============================] - 0s 142us/step - loss: 1.9222e-07 - categorical_accuracy: 1.0000 - val_loss: 7.8691e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "240/240 [==============================] - 0s 153us/step - loss: 1.9024e-07 - categorical_accuracy: 1.0000 - val_loss: 7.8710e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 1.8875e-07 - categorical_accuracy: 1.0000 - val_loss: 7.8631e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "240/240 [==============================] - 0s 130us/step - loss: 1.8726e-07 - categorical_accuracy: 1.0000 - val_loss: 7.8770e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 1.8477e-07 - categorical_accuracy: 1.0000 - val_loss: 7.8432e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "240/240 [==============================] - 0s 121us/step - loss: 1.8428e-07 - categorical_accuracy: 1.0000 - val_loss: 7.8095e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 1.8229e-07 - categorical_accuracy: 1.0000 - val_loss: 7.8154e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "240/240 [==============================] - 0s 236us/step - loss: 1.8080e-07 - categorical_accuracy: 1.0000 - val_loss: 7.8293e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "240/240 [==============================] - 0s 180us/step - loss: 1.7931e-07 - categorical_accuracy: 1.0000 - val_loss: 7.7737e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "240/240 [==============================] - 0s 143us/step - loss: 1.7832e-07 - categorical_accuracy: 1.0000 - val_loss: 7.7995e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "240/240 [==============================] - 0s 133us/step - loss: 1.7534e-07 - categorical_accuracy: 1.0000 - val_loss: 7.7737e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "240/240 [==============================] - 0s 98us/step - loss: 1.7385e-07 - categorical_accuracy: 1.0000 - val_loss: 7.7697e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "240/240 [==============================] - 0s 126us/step - loss: 1.7236e-07 - categorical_accuracy: 1.0000 - val_loss: 7.7082e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "240/240 [==============================] - 0s 94us/step - loss: 1.7136e-07 - categorical_accuracy: 1.0000 - val_loss: 7.7419e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "240/240 [==============================] - 0s 140us/step - loss: 1.6987e-07 - categorical_accuracy: 1.0000 - val_loss: 7.7300e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "240/240 [==============================] - 0s 96us/step - loss: 1.6838e-07 - categorical_accuracy: 1.0000 - val_loss: 7.6565e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 1.6789e-07 - categorical_accuracy: 1.0000 - val_loss: 7.6207e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "240/240 [==============================] - 0s 98us/step - loss: 1.6540e-07 - categorical_accuracy: 1.0000 - val_loss: 7.6386e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 1.6342e-07 - categorical_accuracy: 1.0000 - val_loss: 7.5770e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "240/240 [==============================] - 0s 91us/step - loss: 1.6342e-07 - categorical_accuracy: 1.0000 - val_loss: 7.5770e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "240/240 [==============================] - 0s 160us/step - loss: 1.6143e-07 - categorical_accuracy: 1.0000 - val_loss: 7.5631e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "240/240 [==============================] - 0s 153us/step - loss: 1.6093e-07 - categorical_accuracy: 1.0000 - val_loss: 7.5373e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "240/240 [==============================] - 0s 165us/step - loss: 1.5994e-07 - categorical_accuracy: 1.0000 - val_loss: 7.5174e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "240/240 [==============================] - 0s 188us/step - loss: 1.5895e-07 - categorical_accuracy: 1.0000 - val_loss: 7.4479e-06 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 416/500\n",
      "240/240 [==============================] - 0s 132us/step - loss: 1.5646e-07 - categorical_accuracy: 1.0000 - val_loss: 7.4241e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "240/240 [==============================] - 0s 127us/step - loss: 1.5547e-07 - categorical_accuracy: 1.0000 - val_loss: 7.4201e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "240/240 [==============================] - 0s 126us/step - loss: 1.5398e-07 - categorical_accuracy: 1.0000 - val_loss: 7.4062e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "240/240 [==============================] - 0s 118us/step - loss: 1.5249e-07 - categorical_accuracy: 1.0000 - val_loss: 7.3824e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "240/240 [==============================] - 0s 130us/step - loss: 1.5199e-07 - categorical_accuracy: 1.0000 - val_loss: 7.3665e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "240/240 [==============================] - 0s 99us/step - loss: 1.5050e-07 - categorical_accuracy: 1.0000 - val_loss: 7.3724e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "240/240 [==============================] - 0s 123us/step - loss: 1.4951e-07 - categorical_accuracy: 1.0000 - val_loss: 7.3764e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "240/240 [==============================] - 0s 131us/step - loss: 1.4851e-07 - categorical_accuracy: 1.0000 - val_loss: 7.3406e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 1.4504e-07 - categorical_accuracy: 1.0000 - val_loss: 7.3009e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "240/240 [==============================] - 0s 162us/step - loss: 1.4404e-07 - categorical_accuracy: 1.0000 - val_loss: 7.2572e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "240/240 [==============================] - 0s 134us/step - loss: 1.4355e-07 - categorical_accuracy: 1.0000 - val_loss: 7.2234e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "240/240 [==============================] - 0s 147us/step - loss: 1.4206e-07 - categorical_accuracy: 1.0000 - val_loss: 7.2274e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "240/240 [==============================] - 0s 155us/step - loss: 1.4106e-07 - categorical_accuracy: 1.0000 - val_loss: 7.1817e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "240/240 [==============================] - 0s 137us/step - loss: 1.3908e-07 - categorical_accuracy: 1.0000 - val_loss: 7.1420e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "240/240 [==============================] - 0s 151us/step - loss: 1.3808e-07 - categorical_accuracy: 1.0000 - val_loss: 7.0824e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "240/240 [==============================] - 0s 182us/step - loss: 1.3659e-07 - categorical_accuracy: 1.0000 - val_loss: 7.0665e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "240/240 [==============================] - 0s 150us/step - loss: 1.3510e-07 - categorical_accuracy: 1.0000 - val_loss: 7.0546e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "240/240 [==============================] - 0s 138us/step - loss: 1.3411e-07 - categorical_accuracy: 1.0000 - val_loss: 7.0645e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "240/240 [==============================] - 0s 138us/step - loss: 1.3312e-07 - categorical_accuracy: 1.0000 - val_loss: 7.0188e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "240/240 [==============================] - 0s 147us/step - loss: 1.3212e-07 - categorical_accuracy: 1.0000 - val_loss: 6.9851e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 1.3113e-07 - categorical_accuracy: 1.0000 - val_loss: 6.9771e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "240/240 [==============================] - 0s 90us/step - loss: 1.3063e-07 - categorical_accuracy: 1.0000 - val_loss: 6.9493e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "240/240 [==============================] - 0s 148us/step - loss: 1.2964e-07 - categorical_accuracy: 1.0000 - val_loss: 6.9533e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "240/240 [==============================] - 0s 162us/step - loss: 1.2765e-07 - categorical_accuracy: 1.0000 - val_loss: 6.9016e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "240/240 [==============================] - 0s 144us/step - loss: 1.2666e-07 - categorical_accuracy: 1.0000 - val_loss: 6.8996e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 1.2666e-07 - categorical_accuracy: 1.0000 - val_loss: 6.8877e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "240/240 [==============================] - 0s 126us/step - loss: 1.2517e-07 - categorical_accuracy: 1.0000 - val_loss: 6.8798e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "240/240 [==============================] - 0s 138us/step - loss: 1.2418e-07 - categorical_accuracy: 1.0000 - val_loss: 6.8400e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 1.2269e-07 - categorical_accuracy: 1.0000 - val_loss: 6.8361e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "240/240 [==============================] - 0s 143us/step - loss: 1.2020e-07 - categorical_accuracy: 1.0000 - val_loss: 6.8103e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "240/240 [==============================] - 0s 152us/step - loss: 1.1971e-07 - categorical_accuracy: 1.0000 - val_loss: 6.7725e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "240/240 [==============================] - 0s 137us/step - loss: 1.1971e-07 - categorical_accuracy: 1.0000 - val_loss: 6.7268e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "240/240 [==============================] - 0s 136us/step - loss: 1.1871e-07 - categorical_accuracy: 1.0000 - val_loss: 6.7149e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "240/240 [==============================] - 0s 139us/step - loss: 1.1772e-07 - categorical_accuracy: 1.0000 - val_loss: 6.7149e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 1.1722e-07 - categorical_accuracy: 1.0000 - val_loss: 6.6871e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "240/240 [==============================] - 0s 92us/step - loss: 1.1623e-07 - categorical_accuracy: 1.0000 - val_loss: 6.6116e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "240/240 [==============================] - 0s 129us/step - loss: 1.1623e-07 - categorical_accuracy: 1.0000 - val_loss: 6.6295e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "240/240 [==============================] - 0s 133us/step - loss: 1.1424e-07 - categorical_accuracy: 1.0000 - val_loss: 6.5957e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "240/240 [==============================] - 0s 147us/step - loss: 1.1325e-07 - categorical_accuracy: 1.0000 - val_loss: 6.5639e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "240/240 [==============================] - 0s 132us/step - loss: 1.1275e-07 - categorical_accuracy: 1.0000 - val_loss: 6.5500e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "240/240 [==============================] - 0s 142us/step - loss: 1.1226e-07 - categorical_accuracy: 1.0000 - val_loss: 6.5321e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 1.1027e-07 - categorical_accuracy: 1.0000 - val_loss: 6.4884e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 1.0878e-07 - categorical_accuracy: 1.0000 - val_loss: 6.4229e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 1.0828e-07 - categorical_accuracy: 1.0000 - val_loss: 6.3971e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "240/240 [==============================] - 0s 138us/step - loss: 1.0729e-07 - categorical_accuracy: 1.0000 - val_loss: 6.4288e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "240/240 [==============================] - 0s 161us/step - loss: 1.0629e-07 - categorical_accuracy: 1.0000 - val_loss: 6.4070e-06 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/500\n",
      "240/240 [==============================] - 0s 129us/step - loss: 1.0431e-07 - categorical_accuracy: 1.0000 - val_loss: 6.4169e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 1.0282e-07 - categorical_accuracy: 1.0000 - val_loss: 6.4388e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 1.0232e-07 - categorical_accuracy: 1.0000 - val_loss: 6.3732e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "240/240 [==============================] - 0s 119us/step - loss: 1.0033e-07 - categorical_accuracy: 1.0000 - val_loss: 6.3911e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "240/240 [==============================] - 0s 143us/step - loss: 9.9838e-08 - categorical_accuracy: 1.0000 - val_loss: 6.3871e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "240/240 [==============================] - 0s 148us/step - loss: 9.8844e-08 - categorical_accuracy: 1.0000 - val_loss: 6.3136e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "240/240 [==============================] - 0s 135us/step - loss: 9.8348e-08 - categorical_accuracy: 1.0000 - val_loss: 6.3037e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "240/240 [==============================] - 0s 117us/step - loss: 9.6857e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2798e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "240/240 [==============================] - 0s 135us/step - loss: 9.6361e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2798e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 9.5864e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2739e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 9.4871e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2918e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "240/240 [==============================] - 0s 118us/step - loss: 9.4871e-08 - categorical_accuracy: 1.0000 - val_loss: 6.3057e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "240/240 [==============================] - 0s 130us/step - loss: 9.3877e-08 - categorical_accuracy: 1.0000 - val_loss: 6.3176e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "240/240 [==============================] - 0s 122us/step - loss: 9.2387e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2798e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 9.1890e-08 - categorical_accuracy: 1.0000 - val_loss: 6.3096e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "240/240 [==============================] - 0s 130us/step - loss: 9.1394e-08 - categorical_accuracy: 1.0000 - val_loss: 6.3116e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 9.0400e-08 - categorical_accuracy: 1.0000 - val_loss: 6.3335e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "240/240 [==============================] - 0s 124us/step - loss: 8.9407e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2997e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "240/240 [==============================] - 0s 95us/step - loss: 8.8910e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2918e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "240/240 [==============================] - 0s 119us/step - loss: 8.7917e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2957e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "240/240 [==============================] - 0s 122us/step - loss: 8.7420e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2818e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 8.5930e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2997e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "240/240 [==============================] - 0s 86us/step - loss: 8.5930e-08 - categorical_accuracy: 1.0000 - val_loss: 6.3235e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "240/240 [==============================] - 0s 126us/step - loss: 8.3943e-08 - categorical_accuracy: 1.0000 - val_loss: 6.3017e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "240/240 [==============================] - 0s 134us/step - loss: 8.3446e-08 - categorical_accuracy: 1.0000 - val_loss: 6.3216e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "240/240 [==============================] - 0s 162us/step - loss: 8.2950e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2779e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "240/240 [==============================] - 0s 116us/step - loss: 8.1956e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2918e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "240/240 [==============================] - 0s 129us/step - loss: 8.0466e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2957e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "240/240 [==============================] - 0s 124us/step - loss: 7.9969e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2818e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "240/240 [==============================] - 0s 94us/step - loss: 7.9473e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2600e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "240/240 [==============================] - 0s 121us/step - loss: 7.9473e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2520e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "240/240 [==============================] - 0s 100us/step - loss: 7.8976e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2739e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "240/240 [==============================] - 0s 92us/step - loss: 7.8479e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2620e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 7.7983e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2222e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 7.6493e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2222e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "240/240 [==============================] - 0s 149us/step - loss: 7.5996e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2143e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "240/240 [==============================] - 0s 183us/step - loss: 7.5002e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2143e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "240/240 [==============================] - 0s 121us/step - loss: 7.4506e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2302e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "240/240 [==============================] - 0s 118us/step - loss: 7.4506e-08 - categorical_accuracy: 1.0000 - val_loss: 6.2044e-06 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fd01a7919d0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=500, batch_size=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_rh.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_rh.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X)\n",
    "ytrue = np.argmax(y, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[200,   0],\n",
       "        [  0, 100]],\n",
       "\n",
       "       [[200,   0],\n",
       "        [  0, 100]],\n",
       "\n",
       "       [[200,   0],\n",
       "        [  0, 100]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model_rh.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_rh.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4\n",
    "min_detection_confidence = 0.5\n",
    "min_tracking_confidence = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real time detection and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=min_detection_confidence, \n",
    "                          min_tracking_confidence=min_tracking_confidence) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        h, w, c = frame.shape\n",
    "\n",
    "        \n",
    "        # make detection\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        \n",
    "        cv2.rectangle(frame, (0+int(0.03*h),int(h-0.14*h)), (0+int(0.75*h), int(h-0.015*h)), color,-1)\n",
    "                         \n",
    "            \n",
    "        for i in range(len(labels)):\n",
    "            cv2.rectangle(frame, (70, 10+ i*int(50)), (70+0, 60+ i*int(50)), color,-1)\n",
    "            cv2.putText(frame, labels[i], (10, 50+ i*int(50)), cv2.FONT_HERSHEY_SIMPLEX, 2,(0,255,0), 4, cv2.LINE_AA)\n",
    "\n",
    "        # perform prediction with relative probability\n",
    "        if results.right_hand_landmarks:\n",
    "            for i in range(len(labels)):\n",
    "                cv2.rectangle(frame, (70, 10+ i*int(50)), (70+int(model.predict(np.array([points_detection(results)]))[0][i]*100)*3, 60+ i*int(50)), color,-1)\n",
    "\n",
    "                cv2.putText(frame, labels[i], (10, 50+ i*int(50)), cv2.FONT_HERSHEY_SIMPLEX, 2,(0,255,0), 4, cv2.LINE_AA)\n",
    "\n",
    "            prediction = labels[np.argmax(model.predict(np.array([points_detection(results)])))]\n",
    "            pred_prob = int(np.max(model.predict(np.array([points_detection(results)])))*100)\n",
    "\n",
    "            # add text with prediction\n",
    "            if pred_prob > int(threshold*100):\n",
    "                cv2.putText(frame, f'{prediction.capitalize()} ({pred_prob}%)', \n",
    "                            (0+int(0.05*h),h-int(0.05*h)), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            2 ,\n",
    "                            (0,255,0), \n",
    "                            4, \n",
    "                            cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.putText(frame, 'Detecting Hand', \n",
    "                            (0+int(0.05*h),h-int(0.05*h)), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            2 ,\n",
    "                            (0,255,0), \n",
    "                            4, \n",
    "                            cv2.LINE_AA)\n",
    "        \n",
    "        else:\n",
    "                cv2.putText(frame, 'Detecting Hand', \n",
    "                            (0+int(0.05*h),h-int(0.05*h)), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            2,\n",
    "                            (0,255,0), \n",
    "                            4, \n",
    "                            cv2.LINE_AA)\n",
    "\n",
    "            \n",
    "        #draw_landmarks_custom(frame, results)\n",
    "  \n",
    "        cv2.imshow('LIS', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'landmark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0d/9g1khm697bqbncyfq3gmq4tc0000gn/T/ipykernel_67613/294000958.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoints_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/0d/9g1khm697bqbncyfq3gmq4tc0000gn/T/ipykernel_67613/405856139.py\u001b[0m in \u001b[0;36mpoints_detection\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpoints_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mxMax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_hand_landmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mxMin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_hand_landmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0myMax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_hand_landmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'landmark'"
     ]
    }
   ],
   "source": [
    "model.predict(np.array([points_detection(results)]))[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
