{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPEN-CV PROJECT: LIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Holistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    \n",
    "def draw_landmarks_custom(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,255),thickness=1, circle_radius=1),\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,255),thickness=1, circle_radius=1),\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10),thickness=1, circle_radius=1),\n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121),thickness=1, circle_radius=1),\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,0),thickness=3, circle_radius=5),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,0),thickness=3, circle_radius=5),\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,0),thickness=3, circle_radius=5),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,0),thickness=3, circle_radius=5),\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0d/9g1khm697bqbncyfq3gmq4tc0000gn/T/ipykernel_60781/4282457365.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mblack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1080\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1920\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m#frame = cv2.flip(frame,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, \n",
    "                          min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        black = np.zeros((1080, 1920, 3))\n",
    "        ret, frame = cap.read()\n",
    "        #frame = cv2.flip(frame,1)\n",
    "        \n",
    "        # make detection\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        points_rh_x = []\n",
    "        points_rh_y = []\n",
    "        if results.right_hand_landmarks:\n",
    "            for i in range(21):\n",
    "                points_rh_x.append(results.right_hand_landmarks.landmark[i].x)\n",
    "                points_rh_y.append(results.right_hand_landmarks.landmark[i].y)\n",
    "            max_x = max(points_rh_x)\n",
    "            min_x = min(points_rh_x)\n",
    "            max_y = max(points_rh_y)\n",
    "            min_y = min(points_rh_y)\n",
    "\n",
    "            h, w, c = frame.shape\n",
    "            start_point = (int(min_x*w), int(min_y*h))\n",
    "\n",
    "            # Ending coordinate, here (220, 220)\n",
    "            # represents the bottom right corner of rectangle\n",
    "            end_point = (int(max_x*w), int(max_y*h))\n",
    "\n",
    "            # Blue color in BGR\n",
    "            color = (255, 0, 0)\n",
    "\n",
    "            # Line thickness of 2 px\n",
    "            thickness = 1\n",
    "\n",
    "            # Using cv2.rectangle() method\n",
    "            # Draw a rectangle with blue line borders of thickness of 2 px\n",
    "            image = cv2.rectangle(frame, start_point, end_point, color, thickness)\n",
    "            \n",
    "            image = cv2.line(frame, (int(min_x*w), int(min_y*h)), (int(min_x*w)+ int((int(max_x*w)-int(min_x*w))/5), int(min_y*h)), color, 5)\n",
    "            image = cv2.line(frame, (int(max_x*w), int(min_y*h)), (int(max_x*w)- int((int(max_x*w)-int(min_x*w))/5), int(min_y*h)), color, 5)\n",
    "            image = cv2.line(frame, (int(min_x*w), int(max_y*h)), (int(min_x*w)+ int((int(max_x*w)-int(min_x*w))/5), int(max_y*h)), color, 5)\n",
    "            image = cv2.line(frame, (int(max_x*w), int(max_y*h)), (int(max_x*w)- int((int(max_x*w)-int(min_x*w))/5), int(max_y*h)), color, 5)\n",
    "            \n",
    "            image = cv2.line(frame, (int(min_x*w), int(min_y*h)), (int(min_x*w), int(min_y*h)+ int((int(max_y*h)-int(min_y*h))/5)), color, 5)\n",
    "            image = cv2.line(frame, (int(min_x*w), int(max_y*h)), (int(min_x*w), int(max_y*h)- int((int(max_y*h)-int(min_y*h))/5)), color, 5)\n",
    "            image = cv2.line(frame, (int(max_x*w), int(min_y*h)), (int(max_x*w), int(min_y*h)+ int((int(max_y*h)-int(min_y*h))/5)), color, 5)\n",
    "            image = cv2.line(frame, (int(max_x*w), int(max_y*h)), (int(max_x*w), int(max_y*h)- int((int(max_y*h)-int(min_y*h))/5)), color, 5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        draw_landmarks_custom(frame, results)\n",
    "        \n",
    "        cv2.imshow('LIS', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract point for training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_detection(results):\n",
    "    rh = np.array([[points.x, points.y, points.z] for points in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    # lh = np.array([[points.x, points.y, points.z] for points in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    # po = np.array([[points.x, points.y, points.z] for points in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(99)\n",
    "    # return np.concatenate([lh, rh, po])\n",
    "    return rh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Folders for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('LIS_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set number of output and number of sample for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(['a', 'b', 'c']) # put the entire alphabet in the future\n",
    "no_sequences = 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "#no_sequences = no_sequences+1\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "    for label in labels:\n",
    "        for id in range(no_sequences):\n",
    "    \n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # make detection\n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "            draw_landmarks_custom(frame, results)\n",
    "\n",
    "            if id == 0:\n",
    "                cv2.putText(frame, 'STARTING COLLECTION', (120,200), cv2.FONT_HERSHEY_SIMPLEX, 1 ,(0,255,0), 4, cv2.LINE_AA)\n",
    "                #cv2.putText(frame, f'Collecting frame {id} for {label}', (15,32), cv2.FONT_HERSHEY_SIMPLEX, 1 ,(0,255,0), 4, cv2.LINE_AA)\n",
    "                cv2.imshow('LIS', frame)\n",
    "                cv2.waitKey(1000)\n",
    "            else:\n",
    "                data.append(points_detection(results))\n",
    "                cv2.putText(frame, f'Collecting frame {id} for {label}', (15,32), cv2.FONT_HERSHEY_SIMPLEX, 1 ,(0,255,0), 4, cv2.LINE_AA) \n",
    "                cv2.waitKey(100)\n",
    "                cv2.imshow('LIS', frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    100\n",
      "b    100\n",
      "c    100\n",
      "Name: y, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.348107</td>\n",
       "      <td>0.762331</td>\n",
       "      <td>1.513924e-07</td>\n",
       "      <td>0.383289</td>\n",
       "      <td>0.726162</td>\n",
       "      <td>-0.017568</td>\n",
       "      <td>0.416940</td>\n",
       "      <td>0.658651</td>\n",
       "      <td>-0.027685</td>\n",
       "      <td>0.436927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293984</td>\n",
       "      <td>0.535787</td>\n",
       "      <td>-0.046685</td>\n",
       "      <td>0.314174</td>\n",
       "      <td>0.575904</td>\n",
       "      <td>-0.041996</td>\n",
       "      <td>0.318744</td>\n",
       "      <td>0.616403</td>\n",
       "      <td>-0.033627</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.260318</td>\n",
       "      <td>0.592471</td>\n",
       "      <td>2.711663e-07</td>\n",
       "      <td>0.299940</td>\n",
       "      <td>0.552299</td>\n",
       "      <td>-0.016765</td>\n",
       "      <td>0.331290</td>\n",
       "      <td>0.489124</td>\n",
       "      <td>-0.024033</td>\n",
       "      <td>0.355295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204349</td>\n",
       "      <td>0.364516</td>\n",
       "      <td>-0.032928</td>\n",
       "      <td>0.195269</td>\n",
       "      <td>0.328356</td>\n",
       "      <td>-0.037381</td>\n",
       "      <td>0.189226</td>\n",
       "      <td>0.290290</td>\n",
       "      <td>-0.040298</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.231843</td>\n",
       "      <td>0.605535</td>\n",
       "      <td>4.170414e-07</td>\n",
       "      <td>0.271172</td>\n",
       "      <td>0.566475</td>\n",
       "      <td>-0.020217</td>\n",
       "      <td>0.302637</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>-0.028512</td>\n",
       "      <td>0.330520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171941</td>\n",
       "      <td>0.387143</td>\n",
       "      <td>-0.028485</td>\n",
       "      <td>0.159777</td>\n",
       "      <td>0.356254</td>\n",
       "      <td>-0.034239</td>\n",
       "      <td>0.151011</td>\n",
       "      <td>0.321798</td>\n",
       "      <td>-0.037927</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.226641</td>\n",
       "      <td>0.607650</td>\n",
       "      <td>4.768788e-07</td>\n",
       "      <td>0.266352</td>\n",
       "      <td>0.572120</td>\n",
       "      <td>-0.024059</td>\n",
       "      <td>0.296532</td>\n",
       "      <td>0.512238</td>\n",
       "      <td>-0.035645</td>\n",
       "      <td>0.322135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161482</td>\n",
       "      <td>0.385211</td>\n",
       "      <td>-0.027898</td>\n",
       "      <td>0.148890</td>\n",
       "      <td>0.352443</td>\n",
       "      <td>-0.032937</td>\n",
       "      <td>0.139442</td>\n",
       "      <td>0.317408</td>\n",
       "      <td>-0.035849</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.236175</td>\n",
       "      <td>0.586870</td>\n",
       "      <td>4.475519e-07</td>\n",
       "      <td>0.274260</td>\n",
       "      <td>0.549129</td>\n",
       "      <td>-0.021151</td>\n",
       "      <td>0.305717</td>\n",
       "      <td>0.494487</td>\n",
       "      <td>-0.032243</td>\n",
       "      <td>0.333054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172720</td>\n",
       "      <td>0.373300</td>\n",
       "      <td>-0.034118</td>\n",
       "      <td>0.159851</td>\n",
       "      <td>0.342033</td>\n",
       "      <td>-0.040299</td>\n",
       "      <td>0.150559</td>\n",
       "      <td>0.307385</td>\n",
       "      <td>-0.044336</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.223077</td>\n",
       "      <td>0.692420</td>\n",
       "      <td>3.894357e-07</td>\n",
       "      <td>0.248824</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>-0.023718</td>\n",
       "      <td>0.254819</td>\n",
       "      <td>0.576426</td>\n",
       "      <td>-0.030063</td>\n",
       "      <td>0.228389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184256</td>\n",
       "      <td>0.509881</td>\n",
       "      <td>-0.030502</td>\n",
       "      <td>0.191375</td>\n",
       "      <td>0.549300</td>\n",
       "      <td>-0.030929</td>\n",
       "      <td>0.197946</td>\n",
       "      <td>0.575726</td>\n",
       "      <td>-0.025005</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.226644</td>\n",
       "      <td>0.674913</td>\n",
       "      <td>3.865667e-07</td>\n",
       "      <td>0.253633</td>\n",
       "      <td>0.633263</td>\n",
       "      <td>-0.023803</td>\n",
       "      <td>0.261131</td>\n",
       "      <td>0.561764</td>\n",
       "      <td>-0.028514</td>\n",
       "      <td>0.236224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192624</td>\n",
       "      <td>0.501300</td>\n",
       "      <td>-0.029023</td>\n",
       "      <td>0.199601</td>\n",
       "      <td>0.540242</td>\n",
       "      <td>-0.030297</td>\n",
       "      <td>0.205384</td>\n",
       "      <td>0.566282</td>\n",
       "      <td>-0.024692</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.232366</td>\n",
       "      <td>0.667414</td>\n",
       "      <td>4.125832e-07</td>\n",
       "      <td>0.259117</td>\n",
       "      <td>0.625021</td>\n",
       "      <td>-0.023452</td>\n",
       "      <td>0.267601</td>\n",
       "      <td>0.553147</td>\n",
       "      <td>-0.029060</td>\n",
       "      <td>0.243854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198557</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>-0.029049</td>\n",
       "      <td>0.204604</td>\n",
       "      <td>0.529479</td>\n",
       "      <td>-0.030411</td>\n",
       "      <td>0.209484</td>\n",
       "      <td>0.554525</td>\n",
       "      <td>-0.024792</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.207053</td>\n",
       "      <td>0.680581</td>\n",
       "      <td>4.259139e-07</td>\n",
       "      <td>0.228962</td>\n",
       "      <td>0.628246</td>\n",
       "      <td>-0.028047</td>\n",
       "      <td>0.226262</td>\n",
       "      <td>0.555153</td>\n",
       "      <td>-0.031905</td>\n",
       "      <td>0.196939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158189</td>\n",
       "      <td>0.506870</td>\n",
       "      <td>-0.020786</td>\n",
       "      <td>0.165650</td>\n",
       "      <td>0.541598</td>\n",
       "      <td>-0.024444</td>\n",
       "      <td>0.174709</td>\n",
       "      <td>0.563394</td>\n",
       "      <td>-0.021212</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.219052</td>\n",
       "      <td>0.657296</td>\n",
       "      <td>3.993095e-07</td>\n",
       "      <td>0.244970</td>\n",
       "      <td>0.614435</td>\n",
       "      <td>-0.024891</td>\n",
       "      <td>0.250519</td>\n",
       "      <td>0.545121</td>\n",
       "      <td>-0.031735</td>\n",
       "      <td>0.220261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174096</td>\n",
       "      <td>0.481204</td>\n",
       "      <td>-0.030455</td>\n",
       "      <td>0.182590</td>\n",
       "      <td>0.517745</td>\n",
       "      <td>-0.030211</td>\n",
       "      <td>0.190686</td>\n",
       "      <td>0.541824</td>\n",
       "      <td>-0.023613</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2         3         4         5         6  \\\n",
       "0    0.348107  0.762331  1.513924e-07  0.383289  0.726162 -0.017568  0.416940   \n",
       "1    0.260318  0.592471  2.711663e-07  0.299940  0.552299 -0.016765  0.331290   \n",
       "2    0.231843  0.605535  4.170414e-07  0.271172  0.566475 -0.020217  0.302637   \n",
       "3    0.226641  0.607650  4.768788e-07  0.266352  0.572120 -0.024059  0.296532   \n",
       "4    0.236175  0.586870  4.475519e-07  0.274260  0.549129 -0.021151  0.305717   \n",
       "..        ...       ...           ...       ...       ...       ...       ...   \n",
       "295  0.223077  0.692420  3.894357e-07  0.248824  0.649462 -0.023718  0.254819   \n",
       "296  0.226644  0.674913  3.865667e-07  0.253633  0.633263 -0.023803  0.261131   \n",
       "297  0.232366  0.667414  4.125832e-07  0.259117  0.625021 -0.023452  0.267601   \n",
       "298  0.207053  0.680581  4.259139e-07  0.228962  0.628246 -0.028047  0.226262   \n",
       "299  0.219052  0.657296  3.993095e-07  0.244970  0.614435 -0.024891  0.250519   \n",
       "\n",
       "            7         8         9  ...        54        55        56  \\\n",
       "0    0.658651 -0.027685  0.436927  ...  0.293984  0.535787 -0.046685   \n",
       "1    0.489124 -0.024033  0.355295  ...  0.204349  0.364516 -0.032928   \n",
       "2    0.508197 -0.028512  0.330520  ...  0.171941  0.387143 -0.028485   \n",
       "3    0.512238 -0.035645  0.322135  ...  0.161482  0.385211 -0.027898   \n",
       "4    0.494487 -0.032243  0.333054  ...  0.172720  0.373300 -0.034118   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "295  0.576426 -0.030063  0.228389  ...  0.184256  0.509881 -0.030502   \n",
       "296  0.561764 -0.028514  0.236224  ...  0.192624  0.501300 -0.029023   \n",
       "297  0.553147 -0.029060  0.243854  ...  0.198557  0.491803 -0.029049   \n",
       "298  0.555153 -0.031905  0.196939  ...  0.158189  0.506870 -0.020786   \n",
       "299  0.545121 -0.031735  0.220261  ...  0.174096  0.481204 -0.030455   \n",
       "\n",
       "           57        58        59        60        61        62  y  \n",
       "0    0.314174  0.575904 -0.041996  0.318744  0.616403 -0.033627  a  \n",
       "1    0.195269  0.328356 -0.037381  0.189226  0.290290 -0.040298  a  \n",
       "2    0.159777  0.356254 -0.034239  0.151011  0.321798 -0.037927  a  \n",
       "3    0.148890  0.352443 -0.032937  0.139442  0.317408 -0.035849  a  \n",
       "4    0.159851  0.342033 -0.040299  0.150559  0.307385 -0.044336  a  \n",
       "..        ...       ...       ...       ...       ...       ... ..  \n",
       "295  0.191375  0.549300 -0.030929  0.197946  0.575726 -0.025005  c  \n",
       "296  0.199601  0.540242 -0.030297  0.205384  0.566282 -0.024692  c  \n",
       "297  0.204604  0.529479 -0.030411  0.209484  0.554525 -0.024792  c  \n",
       "298  0.165650  0.541598 -0.024444  0.174709  0.563394 -0.021212  c  \n",
       "299  0.182590  0.517745 -0.030211  0.190686  0.541824 -0.023613  c  \n",
       "\n",
       "[300 rows x 64 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(np.array(data))\n",
    "y=[]\n",
    "for i in labels:\n",
    "    y = np.concatenate([y, [i] * (no_sequences-1)])\n",
    "df['y'] = y\n",
    "pd.DataFrame(df).to_csv('data.csv')\n",
    "print(df['y'].value_counts())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, MinMaxScaler\n",
    "import datetime\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir=\"logs/scalars/\" + model_name,\n",
    "    histogram_freq=0,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    profile_batch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0, 'b': 1, 'c': 2}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {label:num for num, label in enumerate(labels)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = np.array(df.iloc[:,0:-1])\n",
    "y = np.array(df.iloc[:,-1])\n",
    "\n",
    "# define min max scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# transform data\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# define LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# transform data\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y = onehot_encoder.fit_transform(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(labels.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/500\n",
      "240/240 [==============================] - 0s 647us/step - loss: 0.9863 - categorical_accuracy: 0.5500 - val_loss: 1.3721 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "240/240 [==============================] - 0s 132us/step - loss: 0.8398 - categorical_accuracy: 0.6750 - val_loss: 1.2667 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "240/240 [==============================] - 0s 200us/step - loss: 0.6601 - categorical_accuracy: 0.8333 - val_loss: 1.2606 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "240/240 [==============================] - 0s 338us/step - loss: 0.4384 - categorical_accuracy: 0.9292 - val_loss: 0.9706 - val_categorical_accuracy: 0.6500\n",
      "Epoch 5/500\n",
      "240/240 [==============================] - 0s 177us/step - loss: 0.2260 - categorical_accuracy: 0.9875 - val_loss: 0.3984 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "240/240 [==============================] - 0s 172us/step - loss: 0.1069 - categorical_accuracy: 0.9917 - val_loss: 0.1050 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "240/240 [==============================] - 0s 163us/step - loss: 0.0517 - categorical_accuracy: 0.9917 - val_loss: 0.1772 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "240/240 [==============================] - 0s 450us/step - loss: 0.0403 - categorical_accuracy: 0.9917 - val_loss: 0.0520 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "240/240 [==============================] - 0s 315us/step - loss: 0.0268 - categorical_accuracy: 0.9958 - val_loss: 0.0696 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "240/240 [==============================] - 0s 219us/step - loss: 0.0358 - categorical_accuracy: 0.9958 - val_loss: 0.0147 - val_categorical_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "240/240 [==============================] - 0s 194us/step - loss: 0.0281 - categorical_accuracy: 0.9917 - val_loss: 0.1583 - val_categorical_accuracy: 0.9500\n",
      "Epoch 12/500\n",
      "240/240 [==============================] - 0s 158us/step - loss: 0.0313 - categorical_accuracy: 0.9958 - val_loss: 0.0446 - val_categorical_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "240/240 [==============================] - 0s 324us/step - loss: 0.0215 - categorical_accuracy: 0.9958 - val_loss: 0.0244 - val_categorical_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "240/240 [==============================] - 0s 174us/step - loss: 0.0222 - categorical_accuracy: 0.9958 - val_loss: 0.0625 - val_categorical_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "240/240 [==============================] - 0s 190us/step - loss: 0.0124 - categorical_accuracy: 1.0000 - val_loss: 0.0052 - val_categorical_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0288 - categorical_accuracy: 0.9917 - val_loss: 0.0341 - val_categorical_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "240/240 [==============================] - 0s 213us/step - loss: 0.0096 - categorical_accuracy: 1.0000 - val_loss: 0.0106 - val_categorical_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "240/240 [==============================] - 0s 172us/step - loss: 0.0122 - categorical_accuracy: 0.9958 - val_loss: 0.0329 - val_categorical_accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "240/240 [==============================] - 0s 302us/step - loss: 0.0209 - categorical_accuracy: 0.9917 - val_loss: 0.0093 - val_categorical_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "240/240 [==============================] - 0s 126us/step - loss: 0.0325 - categorical_accuracy: 0.9917 - val_loss: 0.0068 - val_categorical_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "240/240 [==============================] - 0s 126us/step - loss: 0.0199 - categorical_accuracy: 0.9917 - val_loss: 0.0115 - val_categorical_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "240/240 [==============================] - 0s 163us/step - loss: 0.0204 - categorical_accuracy: 0.9958 - val_loss: 0.0478 - val_categorical_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "240/240 [==============================] - 0s 145us/step - loss: 0.0093 - categorical_accuracy: 0.9958 - val_loss: 0.0140 - val_categorical_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "240/240 [==============================] - 0s 207us/step - loss: 0.0098 - categorical_accuracy: 1.0000 - val_loss: 0.0083 - val_categorical_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "240/240 [==============================] - 0s 197us/step - loss: 0.0136 - categorical_accuracy: 0.9958 - val_loss: 0.0326 - val_categorical_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "240/240 [==============================] - 0s 172us/step - loss: 0.0059 - categorical_accuracy: 1.0000 - val_loss: 0.0047 - val_categorical_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "240/240 [==============================] - 0s 182us/step - loss: 0.0060 - categorical_accuracy: 1.0000 - val_loss: 0.0125 - val_categorical_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "240/240 [==============================] - 0s 172us/step - loss: 0.0117 - categorical_accuracy: 0.9958 - val_loss: 0.0378 - val_categorical_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "240/240 [==============================] - 0s 187us/step - loss: 0.0073 - categorical_accuracy: 1.0000 - val_loss: 0.0025 - val_categorical_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "240/240 [==============================] - 0s 170us/step - loss: 0.0158 - categorical_accuracy: 0.9917 - val_loss: 0.2080 - val_categorical_accuracy: 0.8500\n",
      "Epoch 31/500\n",
      "240/240 [==============================] - 0s 169us/step - loss: 0.0259 - categorical_accuracy: 0.9917 - val_loss: 0.0010 - val_categorical_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0095 - categorical_accuracy: 1.0000 - val_loss: 0.0086 - val_categorical_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "240/240 [==============================] - 0s 140us/step - loss: 0.0082 - categorical_accuracy: 0.9958 - val_loss: 0.0077 - val_categorical_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "240/240 [==============================] - 0s 156us/step - loss: 0.0063 - categorical_accuracy: 1.0000 - val_loss: 0.0206 - val_categorical_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "240/240 [==============================] - 0s 174us/step - loss: 0.0045 - categorical_accuracy: 1.0000 - val_loss: 0.0041 - val_categorical_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0050 - categorical_accuracy: 1.0000 - val_loss: 0.0100 - val_categorical_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "240/240 [==============================] - 0s 228us/step - loss: 0.0038 - categorical_accuracy: 1.0000 - val_loss: 0.0086 - val_categorical_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "240/240 [==============================] - 0s 268us/step - loss: 0.0054 - categorical_accuracy: 0.9958 - val_loss: 0.0126 - val_categorical_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "240/240 [==============================] - 0s 175us/step - loss: 0.0044 - categorical_accuracy: 1.0000 - val_loss: 0.0025 - val_categorical_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "240/240 [==============================] - 0s 161us/step - loss: 0.0162 - categorical_accuracy: 0.9958 - val_loss: 0.0123 - val_categorical_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "240/240 [==============================] - 0s 128us/step - loss: 0.0075 - categorical_accuracy: 0.9958 - val_loss: 0.0022 - val_categorical_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "240/240 [==============================] - 0s 306us/step - loss: 0.0185 - categorical_accuracy: 0.9958 - val_loss: 0.0141 - val_categorical_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "240/240 [==============================] - 0s 284us/step - loss: 0.0081 - categorical_accuracy: 1.0000 - val_loss: 7.3148e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "240/240 [==============================] - 0s 133us/step - loss: 0.0103 - categorical_accuracy: 0.9958 - val_loss: 0.0180 - val_categorical_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "240/240 [==============================] - 0s 194us/step - loss: 0.0031 - categorical_accuracy: 1.0000 - val_loss: 0.0048 - val_categorical_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "240/240 [==============================] - 0s 157us/step - loss: 0.0044 - categorical_accuracy: 1.0000 - val_loss: 0.0034 - val_categorical_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "240/240 [==============================] - 0s 139us/step - loss: 0.0029 - categorical_accuracy: 1.0000 - val_loss: 0.0040 - val_categorical_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "240/240 [==============================] - 0s 144us/step - loss: 0.0023 - categorical_accuracy: 1.0000 - val_loss: 0.0036 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500\n",
      "240/240 [==============================] - 0s 186us/step - loss: 0.0021 - categorical_accuracy: 1.0000 - val_loss: 0.0049 - val_categorical_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "240/240 [==============================] - 0s 384us/step - loss: 0.0019 - categorical_accuracy: 1.0000 - val_loss: 0.0039 - val_categorical_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "240/240 [==============================] - 0s 172us/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 0.0034 - val_categorical_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "240/240 [==============================] - 0s 169us/step - loss: 0.0026 - categorical_accuracy: 1.0000 - val_loss: 0.0077 - val_categorical_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "240/240 [==============================] - 0s 164us/step - loss: 0.0037 - categorical_accuracy: 1.0000 - val_loss: 0.0027 - val_categorical_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "240/240 [==============================] - 0s 180us/step - loss: 0.0081 - categorical_accuracy: 0.9958 - val_loss: 0.0326 - val_categorical_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "240/240 [==============================] - 0s 227us/step - loss: 0.0075 - categorical_accuracy: 1.0000 - val_loss: 0.0036 - val_categorical_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "240/240 [==============================] - 0s 203us/step - loss: 0.0187 - categorical_accuracy: 0.9958 - val_loss: 0.2372 - val_categorical_accuracy: 0.8500\n",
      "Epoch 57/500\n",
      "240/240 [==============================] - 0s 204us/step - loss: 0.1006 - categorical_accuracy: 0.9750 - val_loss: 3.6350e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "240/240 [==============================] - 0s 244us/step - loss: 0.0222 - categorical_accuracy: 0.9917 - val_loss: 9.2026e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "240/240 [==============================] - 0s 212us/step - loss: 0.0234 - categorical_accuracy: 0.9917 - val_loss: 0.0078 - val_categorical_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "240/240 [==============================] - 0s 240us/step - loss: 0.0113 - categorical_accuracy: 0.9958 - val_loss: 0.0416 - val_categorical_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "240/240 [==============================] - 0s 178us/step - loss: 0.0020 - categorical_accuracy: 1.0000 - val_loss: 0.0035 - val_categorical_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "240/240 [==============================] - 0s 211us/step - loss: 0.0026 - categorical_accuracy: 1.0000 - val_loss: 0.0010 - val_categorical_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "240/240 [==============================] - 0s 215us/step - loss: 0.0027 - categorical_accuracy: 1.0000 - val_loss: 0.0048 - val_categorical_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "240/240 [==============================] - 0s 180us/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 0.0065 - val_categorical_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "240/240 [==============================] - 0s 177us/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 0.0023 - val_categorical_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "240/240 [==============================] - 0s 210us/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 0.0019 - val_categorical_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "240/240 [==============================] - 0s 239us/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 0.0018 - val_categorical_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "240/240 [==============================] - 0s 183us/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 0.0015 - val_categorical_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "240/240 [==============================] - 0s 95us/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 0.0019 - val_categorical_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "240/240 [==============================] - 0s 203us/step - loss: 9.3347e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0015 - val_categorical_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "240/240 [==============================] - 0s 145us/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 0.0018 - val_categorical_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "240/240 [==============================] - 0s 147us/step - loss: 9.3087e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0021 - val_categorical_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "240/240 [==============================] - 0s 233us/step - loss: 8.4981e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0013 - val_categorical_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "240/240 [==============================] - 0s 143us/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 0.0014 - val_categorical_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "240/240 [==============================] - 0s 159us/step - loss: 8.5979e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0016 - val_categorical_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 8.2209e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0013 - val_categorical_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "240/240 [==============================] - 0s 139us/step - loss: 8.1264e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0012 - val_categorical_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "240/240 [==============================] - 0s 174us/step - loss: 9.8852e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0015 - val_categorical_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "240/240 [==============================] - 0s 153us/step - loss: 6.5077e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "240/240 [==============================] - 0s 244us/step - loss: 9.6383e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0013 - val_categorical_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "240/240 [==============================] - 0s 166us/step - loss: 6.1246e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0022 - val_categorical_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "240/240 [==============================] - 0s 122us/step - loss: 7.6952e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0013 - val_categorical_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "240/240 [==============================] - 0s 160us/step - loss: 0.0010 - categorical_accuracy: 1.0000 - val_loss: 0.0012 - val_categorical_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "240/240 [==============================] - 0s 161us/step - loss: 5.5666e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0020 - val_categorical_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "240/240 [==============================] - 0s 130us/step - loss: 8.3443e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0013 - val_categorical_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 5.5703e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0012 - val_categorical_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "240/240 [==============================] - 0s 229us/step - loss: 5.5869e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0013 - val_categorical_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "240/240 [==============================] - 0s 131us/step - loss: 4.8136e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "240/240 [==============================] - 0s 203us/step - loss: 5.2124e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0012 - val_categorical_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "240/240 [==============================] - 0s 162us/step - loss: 4.8183e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0013 - val_categorical_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "240/240 [==============================] - 0s 145us/step - loss: 4.7769e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 4.4302e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0013 - val_categorical_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "240/240 [==============================] - 0s 172us/step - loss: 4.6983e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "240/240 [==============================] - 0s 165us/step - loss: 5.4201e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "240/240 [==============================] - 0s 134us/step - loss: 5.8645e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0018 - val_categorical_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "240/240 [==============================] - 0s 141us/step - loss: 4.2338e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0012 - val_categorical_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "240/240 [==============================] - 0s 216us/step - loss: 4.2641e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "240/240 [==============================] - 0s 125us/step - loss: 3.7448e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "240/240 [==============================] - 0s 199us/step - loss: 3.6289e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0012 - val_categorical_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "240/240 [==============================] - 0s 142us/step - loss: 3.4584e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "240/240 [==============================] - 0s 150us/step - loss: 3.9742e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0012 - val_categorical_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "240/240 [==============================] - 0s 154us/step - loss: 3.3217e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0012 - val_categorical_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "240/240 [==============================] - 0s 159us/step - loss: 3.4510e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "240/240 [==============================] - 0s 142us/step - loss: 3.4526e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0012 - val_categorical_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "240/240 [==============================] - 0s 185us/step - loss: 3.0511e-04 - categorical_accuracy: 1.0000 - val_loss: 9.5977e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "240/240 [==============================] - 0s 221us/step - loss: 4.2822e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0013 - val_categorical_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "240/240 [==============================] - 0s 215us/step - loss: 4.0703e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0014 - val_categorical_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "240/240 [==============================] - 0s 133us/step - loss: 4.4331e-04 - categorical_accuracy: 1.0000 - val_loss: 9.6937e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "240/240 [==============================] - 0s 218us/step - loss: 2.8723e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 2.9275e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0013 - val_categorical_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "240/240 [==============================] - 0s 143us/step - loss: 2.6609e-04 - categorical_accuracy: 1.0000 - val_loss: 9.1565e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "240/240 [==============================] - 0s 166us/step - loss: 2.9433e-04 - categorical_accuracy: 1.0000 - val_loss: 9.7286e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "240/240 [==============================] - 0s 158us/step - loss: 2.8007e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0014 - val_categorical_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "240/240 [==============================] - 0s 271us/step - loss: 2.6915e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0012 - val_categorical_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "240/240 [==============================] - 0s 159us/step - loss: 2.9294e-04 - categorical_accuracy: 1.0000 - val_loss: 9.9656e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "240/240 [==============================] - 0s 138us/step - loss: 2.8562e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0012 - val_categorical_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "240/240 [==============================] - 0s 168us/step - loss: 2.4482e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "240/240 [==============================] - 0s 139us/step - loss: 2.4459e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0010 - val_categorical_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "240/240 [==============================] - 0s 150us/step - loss: 2.4065e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "240/240 [==============================] - 0s 132us/step - loss: 2.2620e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "240/240 [==============================] - 0s 312us/step - loss: 2.3538e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0010 - val_categorical_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "240/240 [==============================] - 0s 223us/step - loss: 2.0711e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0010 - val_categorical_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "240/240 [==============================] - 0s 289us/step - loss: 2.4197e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "240/240 [==============================] - 0s 176us/step - loss: 2.1523e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0012 - val_categorical_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "240/240 [==============================] - 0s 293us/step - loss: 2.1403e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "240/240 [==============================] - 0s 340us/step - loss: 1.9640e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0010 - val_categorical_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "240/240 [==============================] - 0s 240us/step - loss: 1.9363e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "240/240 [==============================] - 0s 138us/step - loss: 1.9217e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0010 - val_categorical_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "240/240 [==============================] - 0s 224us/step - loss: 2.0073e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0010 - val_categorical_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "240/240 [==============================] - 0s 322us/step - loss: 1.8525e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0010 - val_categorical_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "240/240 [==============================] - 0s 206us/step - loss: 2.1343e-04 - categorical_accuracy: 1.0000 - val_loss: 8.6098e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "240/240 [==============================] - 0s 121us/step - loss: 1.9865e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0015 - val_categorical_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "240/240 [==============================] - 0s 122us/step - loss: 2.0748e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0012 - val_categorical_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "240/240 [==============================] - 0s 143us/step - loss: 2.0721e-04 - categorical_accuracy: 1.0000 - val_loss: 8.9066e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "240/240 [==============================] - 0s 187us/step - loss: 1.6851e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "240/240 [==============================] - 0s 124us/step - loss: 1.6941e-04 - categorical_accuracy: 1.0000 - val_loss: 9.3515e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 1.8096e-04 - categorical_accuracy: 1.0000 - val_loss: 9.4483e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "240/240 [==============================] - 0s 144us/step - loss: 1.5853e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0010 - val_categorical_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "240/240 [==============================] - 0s 133us/step - loss: 1.5727e-04 - categorical_accuracy: 1.0000 - val_loss: 9.4422e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 1.5916e-04 - categorical_accuracy: 1.0000 - val_loss: 9.1855e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 1.4851e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "240/240 [==============================] - 0s 149us/step - loss: 1.5596e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0010 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/500\n",
      "240/240 [==============================] - 0s 161us/step - loss: 1.7770e-04 - categorical_accuracy: 1.0000 - val_loss: 8.3031e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "240/240 [==============================] - 0s 171us/step - loss: 1.4589e-04 - categorical_accuracy: 1.0000 - val_loss: 9.6249e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "240/240 [==============================] - 0s 132us/step - loss: 1.4562e-04 - categorical_accuracy: 1.0000 - val_loss: 8.2579e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "240/240 [==============================] - 0s 149us/step - loss: 1.5520e-04 - categorical_accuracy: 1.0000 - val_loss: 8.7209e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "240/240 [==============================] - 0s 171us/step - loss: 1.3121e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "240/240 [==============================] - 0s 140us/step - loss: 1.3615e-04 - categorical_accuracy: 1.0000 - val_loss: 9.4453e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "240/240 [==============================] - 0s 204us/step - loss: 1.2876e-04 - categorical_accuracy: 1.0000 - val_loss: 8.2143e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "240/240 [==============================] - 0s 162us/step - loss: 1.3611e-04 - categorical_accuracy: 1.0000 - val_loss: 9.2078e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "240/240 [==============================] - 0s 164us/step - loss: 1.3633e-04 - categorical_accuracy: 1.0000 - val_loss: 9.3410e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "240/240 [==============================] - 0s 193us/step - loss: 1.3274e-04 - categorical_accuracy: 1.0000 - val_loss: 8.1795e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "240/240 [==============================] - 0s 176us/step - loss: 1.2316e-04 - categorical_accuracy: 1.0000 - val_loss: 9.0591e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "240/240 [==============================] - 0s 235us/step - loss: 1.2342e-04 - categorical_accuracy: 1.0000 - val_loss: 8.9581e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "240/240 [==============================] - 0s 301us/step - loss: 1.3756e-04 - categorical_accuracy: 1.0000 - val_loss: 8.7375e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "240/240 [==============================] - 0s 203us/step - loss: 1.2851e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0010 - val_categorical_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "240/240 [==============================] - 0s 227us/step - loss: 1.3029e-04 - categorical_accuracy: 1.0000 - val_loss: 8.5176e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "240/240 [==============================] - 0s 141us/step - loss: 1.1479e-04 - categorical_accuracy: 1.0000 - val_loss: 8.4886e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "240/240 [==============================] - 0s 150us/step - loss: 1.1073e-04 - categorical_accuracy: 1.0000 - val_loss: 7.9414e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "240/240 [==============================] - 0s 155us/step - loss: 1.1767e-04 - categorical_accuracy: 1.0000 - val_loss: 8.4694e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "240/240 [==============================] - 0s 162us/step - loss: 1.0764e-04 - categorical_accuracy: 1.0000 - val_loss: 8.8661e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "240/240 [==============================] - 0s 200us/step - loss: 1.1205e-04 - categorical_accuracy: 1.0000 - val_loss: 9.1480e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "240/240 [==============================] - 0s 146us/step - loss: 1.0246e-04 - categorical_accuracy: 1.0000 - val_loss: 8.6030e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "240/240 [==============================] - 0s 163us/step - loss: 1.1078e-04 - categorical_accuracy: 1.0000 - val_loss: 7.6948e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "240/240 [==============================] - 0s 246us/step - loss: 1.0545e-04 - categorical_accuracy: 1.0000 - val_loss: 9.3306e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "240/240 [==============================] - 0s 325us/step - loss: 9.9799e-05 - categorical_accuracy: 1.0000 - val_loss: 6.8331e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "240/240 [==============================] - 0s 183us/step - loss: 1.1090e-04 - categorical_accuracy: 1.0000 - val_loss: 7.3483e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "240/240 [==============================] - 0s 147us/step - loss: 9.3854e-05 - categorical_accuracy: 1.0000 - val_loss: 8.8956e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "240/240 [==============================] - 0s 188us/step - loss: 1.0058e-04 - categorical_accuracy: 1.0000 - val_loss: 8.1999e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "240/240 [==============================] - 0s 152us/step - loss: 1.0723e-04 - categorical_accuracy: 1.0000 - val_loss: 7.9330e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "240/240 [==============================] - 0s 188us/step - loss: 1.0141e-04 - categorical_accuracy: 1.0000 - val_loss: 7.6038e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "240/240 [==============================] - 0s 171us/step - loss: 9.3055e-05 - categorical_accuracy: 1.0000 - val_loss: 8.5995e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "240/240 [==============================] - 0s 221us/step - loss: 9.0324e-05 - categorical_accuracy: 1.0000 - val_loss: 7.9024e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "240/240 [==============================] - 0s 189us/step - loss: 9.0246e-05 - categorical_accuracy: 1.0000 - val_loss: 7.4236e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "240/240 [==============================] - 0s 198us/step - loss: 8.7743e-05 - categorical_accuracy: 1.0000 - val_loss: 7.7183e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "240/240 [==============================] - 0s 130us/step - loss: 9.5628e-05 - categorical_accuracy: 1.0000 - val_loss: 7.8433e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "240/240 [==============================] - 0s 154us/step - loss: 8.3632e-05 - categorical_accuracy: 1.0000 - val_loss: 7.5114e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "240/240 [==============================] - 0s 258us/step - loss: 9.0764e-05 - categorical_accuracy: 1.0000 - val_loss: 7.2177e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "240/240 [==============================] - 0s 306us/step - loss: 8.0028e-05 - categorical_accuracy: 1.0000 - val_loss: 8.2627e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "240/240 [==============================] - 0s 174us/step - loss: 8.1603e-05 - categorical_accuracy: 1.0000 - val_loss: 7.9021e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "240/240 [==============================] - 0s 192us/step - loss: 7.9603e-05 - categorical_accuracy: 1.0000 - val_loss: 7.7356e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "240/240 [==============================] - 0s 208us/step - loss: 8.2082e-05 - categorical_accuracy: 1.0000 - val_loss: 6.9469e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "240/240 [==============================] - 0s 143us/step - loss: 8.5935e-05 - categorical_accuracy: 1.0000 - val_loss: 7.1022e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "240/240 [==============================] - 0s 253us/step - loss: 7.6607e-05 - categorical_accuracy: 1.0000 - val_loss: 8.7871e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "240/240 [==============================] - 0s 169us/step - loss: 7.6334e-05 - categorical_accuracy: 1.0000 - val_loss: 7.9667e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "240/240 [==============================] - 0s 125us/step - loss: 8.3017e-05 - categorical_accuracy: 1.0000 - val_loss: 6.6609e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "240/240 [==============================] - 0s 201us/step - loss: 7.4254e-05 - categorical_accuracy: 1.0000 - val_loss: 8.0378e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "240/240 [==============================] - 0s 189us/step - loss: 7.3086e-05 - categorical_accuracy: 1.0000 - val_loss: 7.9388e-04 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/500\n",
      "240/240 [==============================] - 0s 165us/step - loss: 7.6273e-05 - categorical_accuracy: 1.0000 - val_loss: 7.2170e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "240/240 [==============================] - 0s 146us/step - loss: 7.3128e-05 - categorical_accuracy: 1.0000 - val_loss: 7.6324e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "240/240 [==============================] - 0s 208us/step - loss: 7.3042e-05 - categorical_accuracy: 1.0000 - val_loss: 7.1711e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "240/240 [==============================] - 0s 151us/step - loss: 7.2370e-05 - categorical_accuracy: 1.0000 - val_loss: 8.1444e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "240/240 [==============================] - 0s 129us/step - loss: 7.5417e-05 - categorical_accuracy: 1.0000 - val_loss: 7.0131e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "240/240 [==============================] - 0s 184us/step - loss: 6.8761e-05 - categorical_accuracy: 1.0000 - val_loss: 7.2083e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "240/240 [==============================] - 0s 132us/step - loss: 6.8169e-05 - categorical_accuracy: 1.0000 - val_loss: 7.4700e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "240/240 [==============================] - 0s 170us/step - loss: 7.0303e-05 - categorical_accuracy: 1.0000 - val_loss: 6.4412e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "240/240 [==============================] - 0s 149us/step - loss: 6.9811e-05 - categorical_accuracy: 1.0000 - val_loss: 8.7120e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "240/240 [==============================] - 0s 253us/step - loss: 6.2571e-05 - categorical_accuracy: 1.0000 - val_loss: 7.9365e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "240/240 [==============================] - 0s 159us/step - loss: 6.1696e-05 - categorical_accuracy: 1.0000 - val_loss: 6.6746e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "240/240 [==============================] - 0s 204us/step - loss: 6.3254e-05 - categorical_accuracy: 1.0000 - val_loss: 6.8960e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "240/240 [==============================] - 0s 195us/step - loss: 5.8547e-05 - categorical_accuracy: 1.0000 - val_loss: 6.7380e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "240/240 [==============================] - 0s 123us/step - loss: 6.1072e-05 - categorical_accuracy: 1.0000 - val_loss: 7.3221e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "240/240 [==============================] - 0s 148us/step - loss: 6.3053e-05 - categorical_accuracy: 1.0000 - val_loss: 6.9326e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "240/240 [==============================] - 0s 172us/step - loss: 6.1239e-05 - categorical_accuracy: 1.0000 - val_loss: 6.7009e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "240/240 [==============================] - 0s 116us/step - loss: 5.8120e-05 - categorical_accuracy: 1.0000 - val_loss: 7.2798e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "240/240 [==============================] - 0s 186us/step - loss: 5.8235e-05 - categorical_accuracy: 1.0000 - val_loss: 6.7869e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "240/240 [==============================] - 0s 170us/step - loss: 5.9272e-05 - categorical_accuracy: 1.0000 - val_loss: 6.7826e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "240/240 [==============================] - 0s 145us/step - loss: 5.8350e-05 - categorical_accuracy: 1.0000 - val_loss: 6.9344e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "240/240 [==============================] - 0s 195us/step - loss: 5.6734e-05 - categorical_accuracy: 1.0000 - val_loss: 6.7132e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "240/240 [==============================] - 0s 154us/step - loss: 5.2877e-05 - categorical_accuracy: 1.0000 - val_loss: 7.0393e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "240/240 [==============================] - 0s 194us/step - loss: 5.2923e-05 - categorical_accuracy: 1.0000 - val_loss: 6.5107e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "240/240 [==============================] - 0s 163us/step - loss: 5.2303e-05 - categorical_accuracy: 1.0000 - val_loss: 6.3883e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "240/240 [==============================] - 0s 150us/step - loss: 5.1551e-05 - categorical_accuracy: 1.0000 - val_loss: 6.7382e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "240/240 [==============================] - 0s 126us/step - loss: 5.0922e-05 - categorical_accuracy: 1.0000 - val_loss: 7.2107e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "240/240 [==============================] - 0s 207us/step - loss: 5.1010e-05 - categorical_accuracy: 1.0000 - val_loss: 6.3042e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "240/240 [==============================] - 0s 149us/step - loss: 5.0154e-05 - categorical_accuracy: 1.0000 - val_loss: 6.8529e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "240/240 [==============================] - 0s 186us/step - loss: 5.5221e-05 - categorical_accuracy: 1.0000 - val_loss: 5.8456e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "240/240 [==============================] - 0s 189us/step - loss: 4.8070e-05 - categorical_accuracy: 1.0000 - val_loss: 6.9268e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "240/240 [==============================] - 0s 136us/step - loss: 4.8751e-05 - categorical_accuracy: 1.0000 - val_loss: 6.5125e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "240/240 [==============================] - 0s 180us/step - loss: 4.6990e-05 - categorical_accuracy: 1.0000 - val_loss: 5.7740e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "240/240 [==============================] - 0s 201us/step - loss: 4.7309e-05 - categorical_accuracy: 1.0000 - val_loss: 6.3434e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "240/240 [==============================] - 0s 185us/step - loss: 4.7740e-05 - categorical_accuracy: 1.0000 - val_loss: 7.4376e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "240/240 [==============================] - 0s 154us/step - loss: 4.5229e-05 - categorical_accuracy: 1.0000 - val_loss: 6.9712e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "240/240 [==============================] - 0s 207us/step - loss: 4.9510e-05 - categorical_accuracy: 1.0000 - val_loss: 6.1464e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "240/240 [==============================] - 0s 144us/step - loss: 4.3956e-05 - categorical_accuracy: 1.0000 - val_loss: 6.3616e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "240/240 [==============================] - 0s 145us/step - loss: 4.6753e-05 - categorical_accuracy: 1.0000 - val_loss: 6.9440e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "240/240 [==============================] - 0s 139us/step - loss: 4.2993e-05 - categorical_accuracy: 1.0000 - val_loss: 6.1825e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "240/240 [==============================] - 0s 176us/step - loss: 4.2899e-05 - categorical_accuracy: 1.0000 - val_loss: 6.2086e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "240/240 [==============================] - 0s 186us/step - loss: 4.4001e-05 - categorical_accuracy: 1.0000 - val_loss: 6.0578e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "240/240 [==============================] - 0s 198us/step - loss: 4.2692e-05 - categorical_accuracy: 1.0000 - val_loss: 6.2535e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "240/240 [==============================] - 0s 193us/step - loss: 4.4058e-05 - categorical_accuracy: 1.0000 - val_loss: 6.3227e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "240/240 [==============================] - 0s 128us/step - loss: 4.3707e-05 - categorical_accuracy: 1.0000 - val_loss: 6.4970e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "240/240 [==============================] - 0s 130us/step - loss: 4.1413e-05 - categorical_accuracy: 1.0000 - val_loss: 6.2497e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "240/240 [==============================] - 0s 130us/step - loss: 4.1192e-05 - categorical_accuracy: 1.0000 - val_loss: 5.3520e-04 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/500\n",
      "240/240 [==============================] - 0s 138us/step - loss: 3.8364e-05 - categorical_accuracy: 1.0000 - val_loss: 6.3668e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "240/240 [==============================] - 0s 138us/step - loss: 3.8935e-05 - categorical_accuracy: 1.0000 - val_loss: 6.8751e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "240/240 [==============================] - 0s 177us/step - loss: 3.7773e-05 - categorical_accuracy: 1.0000 - val_loss: 5.9539e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "240/240 [==============================] - 0s 239us/step - loss: 3.8295e-05 - categorical_accuracy: 1.0000 - val_loss: 6.2390e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "240/240 [==============================] - 0s 122us/step - loss: 3.7366e-05 - categorical_accuracy: 1.0000 - val_loss: 5.8973e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "240/240 [==============================] - 0s 125us/step - loss: 3.6413e-05 - categorical_accuracy: 1.0000 - val_loss: 6.0727e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "240/240 [==============================] - 0s 130us/step - loss: 3.5682e-05 - categorical_accuracy: 1.0000 - val_loss: 5.9486e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "240/240 [==============================] - 0s 142us/step - loss: 3.8899e-05 - categorical_accuracy: 1.0000 - val_loss: 5.6632e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "240/240 [==============================] - 0s 143us/step - loss: 3.5054e-05 - categorical_accuracy: 1.0000 - val_loss: 6.3531e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "240/240 [==============================] - 0s 152us/step - loss: 3.5961e-05 - categorical_accuracy: 1.0000 - val_loss: 6.3149e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "240/240 [==============================] - 0s 180us/step - loss: 3.5885e-05 - categorical_accuracy: 1.0000 - val_loss: 5.7023e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "240/240 [==============================] - 0s 173us/step - loss: 3.2962e-05 - categorical_accuracy: 1.0000 - val_loss: 6.0699e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "240/240 [==============================] - 0s 165us/step - loss: 3.5200e-05 - categorical_accuracy: 1.0000 - val_loss: 5.9805e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "240/240 [==============================] - 0s 167us/step - loss: 3.3033e-05 - categorical_accuracy: 1.0000 - val_loss: 5.7653e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "240/240 [==============================] - 0s 127us/step - loss: 3.6133e-05 - categorical_accuracy: 1.0000 - val_loss: 6.1153e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "240/240 [==============================] - 0s 139us/step - loss: 3.4113e-05 - categorical_accuracy: 1.0000 - val_loss: 5.6284e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "240/240 [==============================] - 0s 214us/step - loss: 3.2155e-05 - categorical_accuracy: 1.0000 - val_loss: 5.9354e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "240/240 [==============================] - 0s 314us/step - loss: 3.1878e-05 - categorical_accuracy: 1.0000 - val_loss: 6.0113e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "240/240 [==============================] - 0s 146us/step - loss: 3.1932e-05 - categorical_accuracy: 1.0000 - val_loss: 5.8826e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "240/240 [==============================] - 0s 133us/step - loss: 3.0432e-05 - categorical_accuracy: 1.0000 - val_loss: 5.9490e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "240/240 [==============================] - 0s 155us/step - loss: 3.0574e-05 - categorical_accuracy: 1.0000 - val_loss: 5.9154e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "240/240 [==============================] - 0s 142us/step - loss: 3.0034e-05 - categorical_accuracy: 1.0000 - val_loss: 5.4776e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "240/240 [==============================] - 0s 125us/step - loss: 3.0750e-05 - categorical_accuracy: 1.0000 - val_loss: 5.2245e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "240/240 [==============================] - 0s 139us/step - loss: 3.0079e-05 - categorical_accuracy: 1.0000 - val_loss: 6.0424e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "240/240 [==============================] - 0s 221us/step - loss: 2.9072e-05 - categorical_accuracy: 1.0000 - val_loss: 5.3028e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "240/240 [==============================] - 0s 159us/step - loss: 3.0005e-05 - categorical_accuracy: 1.0000 - val_loss: 5.8020e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "240/240 [==============================] - 0s 169us/step - loss: 3.0478e-05 - categorical_accuracy: 1.0000 - val_loss: 5.5704e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "240/240 [==============================] - 0s 249us/step - loss: 2.8564e-05 - categorical_accuracy: 1.0000 - val_loss: 5.7055e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "240/240 [==============================] - 0s 154us/step - loss: 2.8618e-05 - categorical_accuracy: 1.0000 - val_loss: 5.4595e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "240/240 [==============================] - 0s 166us/step - loss: 2.8018e-05 - categorical_accuracy: 1.0000 - val_loss: 6.0260e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "240/240 [==============================] - 0s 235us/step - loss: 2.7401e-05 - categorical_accuracy: 1.0000 - val_loss: 5.6916e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "240/240 [==============================] - 0s 133us/step - loss: 2.7849e-05 - categorical_accuracy: 1.0000 - val_loss: 4.9327e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "240/240 [==============================] - 0s 178us/step - loss: 2.7108e-05 - categorical_accuracy: 1.0000 - val_loss: 5.5798e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "240/240 [==============================] - 0s 312us/step - loss: 2.6436e-05 - categorical_accuracy: 1.0000 - val_loss: 5.3923e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "240/240 [==============================] - 0s 130us/step - loss: 2.6105e-05 - categorical_accuracy: 1.0000 - val_loss: 5.4265e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "240/240 [==============================] - 0s 145us/step - loss: 2.7297e-05 - categorical_accuracy: 1.0000 - val_loss: 5.6254e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "240/240 [==============================] - 0s 181us/step - loss: 2.5215e-05 - categorical_accuracy: 1.0000 - val_loss: 5.4903e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "240/240 [==============================] - 0s 209us/step - loss: 2.5648e-05 - categorical_accuracy: 1.0000 - val_loss: 5.1115e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "240/240 [==============================] - 0s 209us/step - loss: 2.5058e-05 - categorical_accuracy: 1.0000 - val_loss: 5.6048e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "240/240 [==============================] - 0s 157us/step - loss: 2.5459e-05 - categorical_accuracy: 1.0000 - val_loss: 5.5274e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "240/240 [==============================] - 0s 151us/step - loss: 2.5656e-05 - categorical_accuracy: 1.0000 - val_loss: 5.4827e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "240/240 [==============================] - 0s 131us/step - loss: 2.4152e-05 - categorical_accuracy: 1.0000 - val_loss: 5.4924e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "240/240 [==============================] - 0s 365us/step - loss: 2.4012e-05 - categorical_accuracy: 1.0000 - val_loss: 5.3951e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "240/240 [==============================] - 0s 249us/step - loss: 2.4040e-05 - categorical_accuracy: 1.0000 - val_loss: 5.1041e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "240/240 [==============================] - 0s 126us/step - loss: 2.3434e-05 - categorical_accuracy: 1.0000 - val_loss: 5.1840e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "240/240 [==============================] - 0s 121us/step - loss: 2.3395e-05 - categorical_accuracy: 1.0000 - val_loss: 5.2127e-04 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/500\n",
      "240/240 [==============================] - 0s 162us/step - loss: 2.3874e-05 - categorical_accuracy: 1.0000 - val_loss: 5.2380e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "240/240 [==============================] - 0s 174us/step - loss: 2.2460e-05 - categorical_accuracy: 1.0000 - val_loss: 5.3588e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "240/240 [==============================] - 0s 175us/step - loss: 2.2501e-05 - categorical_accuracy: 1.0000 - val_loss: 4.6813e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "240/240 [==============================] - 0s 155us/step - loss: 2.2353e-05 - categorical_accuracy: 1.0000 - val_loss: 5.5841e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "240/240 [==============================] - 0s 99us/step - loss: 2.2227e-05 - categorical_accuracy: 1.0000 - val_loss: 5.5123e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "240/240 [==============================] - 0s 197us/step - loss: 2.2288e-05 - categorical_accuracy: 1.0000 - val_loss: 5.2211e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "240/240 [==============================] - 0s 144us/step - loss: 2.2495e-05 - categorical_accuracy: 1.0000 - val_loss: 4.8937e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "240/240 [==============================] - 0s 288us/step - loss: 2.2844e-05 - categorical_accuracy: 1.0000 - val_loss: 5.1060e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "240/240 [==============================] - 0s 226us/step - loss: 2.1620e-05 - categorical_accuracy: 1.0000 - val_loss: 4.9712e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "240/240 [==============================] - 0s 151us/step - loss: 2.1093e-05 - categorical_accuracy: 1.0000 - val_loss: 5.1911e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "240/240 [==============================] - 0s 143us/step - loss: 2.0991e-05 - categorical_accuracy: 1.0000 - val_loss: 5.0079e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "240/240 [==============================] - 0s 186us/step - loss: 2.0579e-05 - categorical_accuracy: 1.0000 - val_loss: 5.0478e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "240/240 [==============================] - 0s 121us/step - loss: 2.0905e-05 - categorical_accuracy: 1.0000 - val_loss: 5.0270e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "240/240 [==============================] - 0s 151us/step - loss: 2.0144e-05 - categorical_accuracy: 1.0000 - val_loss: 5.2680e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "240/240 [==============================] - 0s 128us/step - loss: 2.0222e-05 - categorical_accuracy: 1.0000 - val_loss: 5.2001e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "240/240 [==============================] - 0s 280us/step - loss: 2.1356e-05 - categorical_accuracy: 1.0000 - val_loss: 4.8736e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "240/240 [==============================] - 0s 176us/step - loss: 1.9253e-05 - categorical_accuracy: 1.0000 - val_loss: 5.1964e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "240/240 [==============================] - 0s 148us/step - loss: 1.9921e-05 - categorical_accuracy: 1.0000 - val_loss: 4.7464e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "240/240 [==============================] - 0s 233us/step - loss: 1.9560e-05 - categorical_accuracy: 1.0000 - val_loss: 4.4179e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "240/240 [==============================] - 0s 150us/step - loss: 1.9462e-05 - categorical_accuracy: 1.0000 - val_loss: 4.9693e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "240/240 [==============================] - 0s 171us/step - loss: 1.9021e-05 - categorical_accuracy: 1.0000 - val_loss: 5.0070e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "240/240 [==============================] - 0s 189us/step - loss: 1.8122e-05 - categorical_accuracy: 1.0000 - val_loss: 5.0416e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "240/240 [==============================] - 0s 230us/step - loss: 1.8406e-05 - categorical_accuracy: 1.0000 - val_loss: 4.8479e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "240/240 [==============================] - 0s 168us/step - loss: 1.8336e-05 - categorical_accuracy: 1.0000 - val_loss: 4.7797e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "240/240 [==============================] - 0s 170us/step - loss: 1.8250e-05 - categorical_accuracy: 1.0000 - val_loss: 4.5822e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "240/240 [==============================] - 0s 272us/step - loss: 1.8024e-05 - categorical_accuracy: 1.0000 - val_loss: 5.0241e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "240/240 [==============================] - 0s 130us/step - loss: 1.7680e-05 - categorical_accuracy: 1.0000 - val_loss: 5.1260e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "240/240 [==============================] - 0s 559us/step - loss: 1.8286e-05 - categorical_accuracy: 1.0000 - val_loss: 4.7025e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "240/240 [==============================] - 0s 203us/step - loss: 1.7692e-05 - categorical_accuracy: 1.0000 - val_loss: 4.3457e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "240/240 [==============================] - 0s 192us/step - loss: 1.7330e-05 - categorical_accuracy: 1.0000 - val_loss: 4.6786e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "240/240 [==============================] - 0s 289us/step - loss: 1.6907e-05 - categorical_accuracy: 1.0000 - val_loss: 4.8112e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "240/240 [==============================] - 0s 359us/step - loss: 1.6950e-05 - categorical_accuracy: 1.0000 - val_loss: 5.0180e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "240/240 [==============================] - 0s 142us/step - loss: 1.7729e-05 - categorical_accuracy: 1.0000 - val_loss: 4.6100e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "240/240 [==============================] - 0s 177us/step - loss: 1.7522e-05 - categorical_accuracy: 1.0000 - val_loss: 5.0578e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "240/240 [==============================] - 0s 200us/step - loss: 1.6561e-05 - categorical_accuracy: 1.0000 - val_loss: 4.6523e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "240/240 [==============================] - 0s 183us/step - loss: 1.6489e-05 - categorical_accuracy: 1.0000 - val_loss: 4.1947e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "240/240 [==============================] - 0s 215us/step - loss: 1.6451e-05 - categorical_accuracy: 1.0000 - val_loss: 4.7687e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "240/240 [==============================] - 0s 143us/step - loss: 1.5615e-05 - categorical_accuracy: 1.0000 - val_loss: 4.7920e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "240/240 [==============================] - 0s 123us/step - loss: 1.5758e-05 - categorical_accuracy: 1.0000 - val_loss: 4.5323e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 1.5428e-05 - categorical_accuracy: 1.0000 - val_loss: 4.8002e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 1.6300e-05 - categorical_accuracy: 1.0000 - val_loss: 4.5687e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "240/240 [==============================] - 0s 123us/step - loss: 1.6149e-05 - categorical_accuracy: 1.0000 - val_loss: 5.0448e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "240/240 [==============================] - 0s 134us/step - loss: 1.5689e-05 - categorical_accuracy: 1.0000 - val_loss: 4.8479e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "240/240 [==============================] - 0s 131us/step - loss: 1.5995e-05 - categorical_accuracy: 1.0000 - val_loss: 3.9398e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "240/240 [==============================] - 0s 181us/step - loss: 1.5786e-05 - categorical_accuracy: 1.0000 - val_loss: 4.8984e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "240/240 [==============================] - 0s 177us/step - loss: 1.5143e-05 - categorical_accuracy: 1.0000 - val_loss: 4.4753e-04 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/500\n",
      "240/240 [==============================] - 0s 128us/step - loss: 1.4555e-05 - categorical_accuracy: 1.0000 - val_loss: 4.6378e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "240/240 [==============================] - 0s 133us/step - loss: 1.4436e-05 - categorical_accuracy: 1.0000 - val_loss: 4.6711e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "240/240 [==============================] - 0s 145us/step - loss: 1.4382e-05 - categorical_accuracy: 1.0000 - val_loss: 4.5185e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 1.4414e-05 - categorical_accuracy: 1.0000 - val_loss: 4.2090e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "240/240 [==============================] - 0s 149us/step - loss: 1.4174e-05 - categorical_accuracy: 1.0000 - val_loss: 4.6840e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "240/240 [==============================] - 0s 180us/step - loss: 1.3659e-05 - categorical_accuracy: 1.0000 - val_loss: 4.5156e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "240/240 [==============================] - 0s 153us/step - loss: 1.3981e-05 - categorical_accuracy: 1.0000 - val_loss: 4.4737e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "240/240 [==============================] - 0s 144us/step - loss: 1.4379e-05 - categorical_accuracy: 1.0000 - val_loss: 4.2767e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "240/240 [==============================] - 0s 206us/step - loss: 1.3966e-05 - categorical_accuracy: 1.0000 - val_loss: 4.6452e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "240/240 [==============================] - 0s 124us/step - loss: 1.3721e-05 - categorical_accuracy: 1.0000 - val_loss: 4.6231e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "240/240 [==============================] - 0s 176us/step - loss: 1.3461e-05 - categorical_accuracy: 1.0000 - val_loss: 4.2761e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "240/240 [==============================] - 0s 414us/step - loss: 1.3185e-05 - categorical_accuracy: 1.0000 - val_loss: 4.6374e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "240/240 [==============================] - 0s 166us/step - loss: 1.2744e-05 - categorical_accuracy: 1.0000 - val_loss: 4.6195e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 1.3207e-05 - categorical_accuracy: 1.0000 - val_loss: 4.1166e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 1.3362e-05 - categorical_accuracy: 1.0000 - val_loss: 4.2413e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 1.2403e-05 - categorical_accuracy: 1.0000 - val_loss: 4.2876e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 1.2806e-05 - categorical_accuracy: 1.0000 - val_loss: 4.8484e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "240/240 [==============================] - 0s 144us/step - loss: 1.2424e-05 - categorical_accuracy: 1.0000 - val_loss: 4.2708e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 1.3081e-05 - categorical_accuracy: 1.0000 - val_loss: 4.1846e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "240/240 [==============================] - 0s 179us/step - loss: 1.1874e-05 - categorical_accuracy: 1.0000 - val_loss: 4.4456e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "240/240 [==============================] - 0s 102us/step - loss: 1.2701e-05 - categorical_accuracy: 1.0000 - val_loss: 4.2460e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 1.2059e-05 - categorical_accuracy: 1.0000 - val_loss: 4.2694e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "240/240 [==============================] - 0s 184us/step - loss: 1.2131e-05 - categorical_accuracy: 1.0000 - val_loss: 4.3119e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "240/240 [==============================] - 0s 283us/step - loss: 1.2335e-05 - categorical_accuracy: 1.0000 - val_loss: 4.6475e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "240/240 [==============================] - 0s 253us/step - loss: 1.1981e-05 - categorical_accuracy: 1.0000 - val_loss: 4.1225e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "240/240 [==============================] - 0s 315us/step - loss: 1.2016e-05 - categorical_accuracy: 1.0000 - val_loss: 3.7736e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "240/240 [==============================] - 0s 193us/step - loss: 1.1202e-05 - categorical_accuracy: 1.0000 - val_loss: 4.4563e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "240/240 [==============================] - 0s 204us/step - loss: 1.1086e-05 - categorical_accuracy: 1.0000 - val_loss: 4.3138e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 1.1287e-05 - categorical_accuracy: 1.0000 - val_loss: 3.8660e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "240/240 [==============================] - 0s 131us/step - loss: 1.1232e-05 - categorical_accuracy: 1.0000 - val_loss: 4.0844e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "240/240 [==============================] - 0s 135us/step - loss: 1.0724e-05 - categorical_accuracy: 1.0000 - val_loss: 4.1403e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "240/240 [==============================] - 0s 216us/step - loss: 1.1197e-05 - categorical_accuracy: 1.0000 - val_loss: 4.1594e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "240/240 [==============================] - 0s 163us/step - loss: 1.0761e-05 - categorical_accuracy: 1.0000 - val_loss: 3.9108e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "240/240 [==============================] - 0s 174us/step - loss: 1.0481e-05 - categorical_accuracy: 1.0000 - val_loss: 4.2961e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "240/240 [==============================] - 0s 142us/step - loss: 1.0546e-05 - categorical_accuracy: 1.0000 - val_loss: 4.2051e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "240/240 [==============================] - 0s 147us/step - loss: 1.0642e-05 - categorical_accuracy: 1.0000 - val_loss: 3.9889e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "240/240 [==============================] - 0s 158us/step - loss: 1.0337e-05 - categorical_accuracy: 1.0000 - val_loss: 4.4284e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "240/240 [==============================] - 0s 292us/step - loss: 1.0328e-05 - categorical_accuracy: 1.0000 - val_loss: 3.9050e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "240/240 [==============================] - 0s 145us/step - loss: 1.0202e-05 - categorical_accuracy: 1.0000 - val_loss: 4.2075e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 1.0042e-05 - categorical_accuracy: 1.0000 - val_loss: 4.0998e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "240/240 [==============================] - 0s 161us/step - loss: 1.0042e-05 - categorical_accuracy: 1.0000 - val_loss: 3.7229e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "240/240 [==============================] - 0s 156us/step - loss: 9.9038e-06 - categorical_accuracy: 1.0000 - val_loss: 4.1329e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "240/240 [==============================] - 0s 152us/step - loss: 9.8297e-06 - categorical_accuracy: 1.0000 - val_loss: 4.2005e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "240/240 [==============================] - 0s 187us/step - loss: 9.6102e-06 - categorical_accuracy: 1.0000 - val_loss: 3.9259e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "240/240 [==============================] - 0s 146us/step - loss: 9.6714e-06 - categorical_accuracy: 1.0000 - val_loss: 4.1467e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "240/240 [==============================] - 0s 123us/step - loss: 9.4965e-06 - categorical_accuracy: 1.0000 - val_loss: 3.9998e-04 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373/500\n",
      "240/240 [==============================] - 0s 145us/step - loss: 9.6515e-06 - categorical_accuracy: 1.0000 - val_loss: 3.6859e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "240/240 [==============================] - 0s 217us/step - loss: 9.4449e-06 - categorical_accuracy: 1.0000 - val_loss: 3.7307e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "240/240 [==============================] - 0s 173us/step - loss: 9.1640e-06 - categorical_accuracy: 1.0000 - val_loss: 3.9652e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "240/240 [==============================] - 0s 164us/step - loss: 9.2239e-06 - categorical_accuracy: 1.0000 - val_loss: 4.1339e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "240/240 [==============================] - 0s 262us/step - loss: 9.0061e-06 - categorical_accuracy: 1.0000 - val_loss: 4.0033e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "240/240 [==============================] - 0s 202us/step - loss: 9.1721e-06 - categorical_accuracy: 1.0000 - val_loss: 3.5088e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "240/240 [==============================] - 0s 135us/step - loss: 9.1442e-06 - categorical_accuracy: 1.0000 - val_loss: 3.7663e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "240/240 [==============================] - 0s 173us/step - loss: 8.7285e-06 - categorical_accuracy: 1.0000 - val_loss: 3.8968e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 8.7226e-06 - categorical_accuracy: 1.0000 - val_loss: 3.9668e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "240/240 [==============================] - 0s 153us/step - loss: 8.6615e-06 - categorical_accuracy: 1.0000 - val_loss: 3.6308e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 8.8276e-06 - categorical_accuracy: 1.0000 - val_loss: 3.6317e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "240/240 [==============================] - 0s 326us/step - loss: 8.5637e-06 - categorical_accuracy: 1.0000 - val_loss: 3.9048e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "240/240 [==============================] - 0s 198us/step - loss: 8.3919e-06 - categorical_accuracy: 1.0000 - val_loss: 3.8265e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "240/240 [==============================] - 0s 152us/step - loss: 8.7768e-06 - categorical_accuracy: 1.0000 - val_loss: 3.6672e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "240/240 [==============================] - 0s 129us/step - loss: 8.5814e-06 - categorical_accuracy: 1.0000 - val_loss: 4.0396e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "240/240 [==============================] - 0s 144us/step - loss: 8.5832e-06 - categorical_accuracy: 1.0000 - val_loss: 3.9580e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "240/240 [==============================] - 0s 377us/step - loss: 8.2991e-06 - categorical_accuracy: 1.0000 - val_loss: 3.2806e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "240/240 [==============================] - 0s 219us/step - loss: 9.0426e-06 - categorical_accuracy: 1.0000 - val_loss: 3.3705e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "240/240 [==============================] - 0s 159us/step - loss: 7.8966e-06 - categorical_accuracy: 1.0000 - val_loss: 3.8151e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "240/240 [==============================] - 0s 279us/step - loss: 8.2703e-06 - categorical_accuracy: 1.0000 - val_loss: 4.0555e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "240/240 [==============================] - 0s 181us/step - loss: 8.1337e-06 - categorical_accuracy: 1.0000 - val_loss: 3.6474e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "240/240 [==============================] - 0s 287us/step - loss: 7.9433e-06 - categorical_accuracy: 1.0000 - val_loss: 3.6375e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "240/240 [==============================] - 0s 209us/step - loss: 7.7304e-06 - categorical_accuracy: 1.0000 - val_loss: 3.7686e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "240/240 [==============================] - 0s 179us/step - loss: 7.6402e-06 - categorical_accuracy: 1.0000 - val_loss: 3.6821e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "240/240 [==============================] - 0s 252us/step - loss: 7.9979e-06 - categorical_accuracy: 1.0000 - val_loss: 3.3327e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "240/240 [==============================] - 0s 186us/step - loss: 7.4032e-06 - categorical_accuracy: 1.0000 - val_loss: 3.7094e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "240/240 [==============================] - 0s 292us/step - loss: 7.3988e-06 - categorical_accuracy: 1.0000 - val_loss: 3.7005e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "240/240 [==============================] - 0s 205us/step - loss: 7.5193e-06 - categorical_accuracy: 1.0000 - val_loss: 3.7794e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "240/240 [==============================] - 0s 134us/step - loss: 7.5431e-06 - categorical_accuracy: 1.0000 - val_loss: 3.6057e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "240/240 [==============================] - 0s 128us/step - loss: 7.8939e-06 - categorical_accuracy: 1.0000 - val_loss: 3.5382e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "240/240 [==============================] - 0s 194us/step - loss: 7.4188e-06 - categorical_accuracy: 1.0000 - val_loss: 3.7136e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "240/240 [==============================] - 0s 250us/step - loss: 7.0482e-06 - categorical_accuracy: 1.0000 - val_loss: 3.5650e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "240/240 [==============================] - 0s 265us/step - loss: 7.2283e-06 - categorical_accuracy: 1.0000 - val_loss: 3.4454e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "240/240 [==============================] - 0s 136us/step - loss: 7.1445e-06 - categorical_accuracy: 1.0000 - val_loss: 3.2102e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "240/240 [==============================] - 0s 159us/step - loss: 7.1732e-06 - categorical_accuracy: 1.0000 - val_loss: 3.5120e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "240/240 [==============================] - 0s 213us/step - loss: 6.8953e-06 - categorical_accuracy: 1.0000 - val_loss: 3.7119e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "240/240 [==============================] - 0s 134us/step - loss: 6.8621e-06 - categorical_accuracy: 1.0000 - val_loss: 3.5890e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "240/240 [==============================] - 0s 139us/step - loss: 6.9374e-06 - categorical_accuracy: 1.0000 - val_loss: 3.3810e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "240/240 [==============================] - 0s 214us/step - loss: 6.8709e-06 - categorical_accuracy: 1.0000 - val_loss: 3.5195e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "240/240 [==============================] - 0s 151us/step - loss: 6.6579e-06 - categorical_accuracy: 1.0000 - val_loss: 3.6751e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 6.7342e-06 - categorical_accuracy: 1.0000 - val_loss: 3.3986e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "240/240 [==============================] - 0s 122us/step - loss: 6.4746e-06 - categorical_accuracy: 1.0000 - val_loss: 3.5211e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "240/240 [==============================] - 0s 138us/step - loss: 6.5373e-06 - categorical_accuracy: 1.0000 - val_loss: 3.5843e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "240/240 [==============================] - 0s 128us/step - loss: 6.8554e-06 - categorical_accuracy: 1.0000 - val_loss: 3.2757e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "240/240 [==============================] - 0s 157us/step - loss: 6.3957e-06 - categorical_accuracy: 1.0000 - val_loss: 3.6520e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "240/240 [==============================] - 0s 133us/step - loss: 6.4698e-06 - categorical_accuracy: 1.0000 - val_loss: 3.6246e-04 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419/500\n",
      "240/240 [==============================] - 0s 164us/step - loss: 6.7858e-06 - categorical_accuracy: 1.0000 - val_loss: 3.2074e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 6.1131e-06 - categorical_accuracy: 1.0000 - val_loss: 3.5089e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "240/240 [==============================] - 0s 144us/step - loss: 6.3058e-06 - categorical_accuracy: 1.0000 - val_loss: 3.5817e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "240/240 [==============================] - 0s 144us/step - loss: 6.2617e-06 - categorical_accuracy: 1.0000 - val_loss: 3.3048e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "240/240 [==============================] - 0s 126us/step - loss: 6.0699e-06 - categorical_accuracy: 1.0000 - val_loss: 3.3761e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "240/240 [==============================] - 0s 180us/step - loss: 6.0357e-06 - categorical_accuracy: 1.0000 - val_loss: 3.2566e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "240/240 [==============================] - 0s 142us/step - loss: 5.9290e-06 - categorical_accuracy: 1.0000 - val_loss: 3.4689e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "240/240 [==============================] - 0s 186us/step - loss: 5.9711e-06 - categorical_accuracy: 1.0000 - val_loss: 3.3844e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "240/240 [==============================] - 0s 162us/step - loss: 5.8689e-06 - categorical_accuracy: 1.0000 - val_loss: 3.2746e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "240/240 [==============================] - 0s 224us/step - loss: 5.8381e-06 - categorical_accuracy: 1.0000 - val_loss: 3.2419e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "240/240 [==============================] - 0s 200us/step - loss: 5.8360e-06 - categorical_accuracy: 1.0000 - val_loss: 3.1560e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "240/240 [==============================] - 0s 168us/step - loss: 5.7471e-06 - categorical_accuracy: 1.0000 - val_loss: 3.3718e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "240/240 [==============================] - 0s 209us/step - loss: 5.6667e-06 - categorical_accuracy: 1.0000 - val_loss: 3.4189e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "240/240 [==============================] - 0s 157us/step - loss: 5.5898e-06 - categorical_accuracy: 1.0000 - val_loss: 3.3129e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "240/240 [==============================] - 0s 271us/step - loss: 5.8131e-06 - categorical_accuracy: 1.0000 - val_loss: 3.2158e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "240/240 [==============================] - 0s 306us/step - loss: 5.8221e-06 - categorical_accuracy: 1.0000 - val_loss: 3.6664e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "240/240 [==============================] - 0s 169us/step - loss: 5.7145e-06 - categorical_accuracy: 1.0000 - val_loss: 3.4325e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "240/240 [==============================] - 0s 190us/step - loss: 5.4810e-06 - categorical_accuracy: 1.0000 - val_loss: 3.0076e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "240/240 [==============================] - 0s 204us/step - loss: 5.5192e-06 - categorical_accuracy: 1.0000 - val_loss: 3.2427e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "240/240 [==============================] - 0s 167us/step - loss: 5.3509e-06 - categorical_accuracy: 1.0000 - val_loss: 3.2694e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "240/240 [==============================] - 0s 138us/step - loss: 5.5440e-06 - categorical_accuracy: 1.0000 - val_loss: 3.4126e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "240/240 [==============================] - 0s 271us/step - loss: 5.3136e-06 - categorical_accuracy: 1.0000 - val_loss: 3.2325e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "240/240 [==============================] - 0s 228us/step - loss: 5.3375e-06 - categorical_accuracy: 1.0000 - val_loss: 3.1483e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "240/240 [==============================] - 0s 207us/step - loss: 5.1880e-06 - categorical_accuracy: 1.0000 - val_loss: 3.1240e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "240/240 [==============================] - 0s 158us/step - loss: 5.4729e-06 - categorical_accuracy: 1.0000 - val_loss: 3.0019e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "240/240 [==============================] - 0s 269us/step - loss: 5.0449e-06 - categorical_accuracy: 1.0000 - val_loss: 3.4457e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "240/240 [==============================] - 0s 199us/step - loss: 5.2139e-06 - categorical_accuracy: 1.0000 - val_loss: 3.3437e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "240/240 [==============================] - 0s 160us/step - loss: 5.0927e-06 - categorical_accuracy: 1.0000 - val_loss: 3.1582e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "240/240 [==============================] - 0s 197us/step - loss: 5.0281e-06 - categorical_accuracy: 1.0000 - val_loss: 3.0914e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "240/240 [==============================] - 0s 117us/step - loss: 4.9606e-06 - categorical_accuracy: 1.0000 - val_loss: 3.1025e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "240/240 [==============================] - 0s 225us/step - loss: 4.8811e-06 - categorical_accuracy: 1.0000 - val_loss: 3.1126e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "240/240 [==============================] - 0s 182us/step - loss: 4.8870e-06 - categorical_accuracy: 1.0000 - val_loss: 3.2515e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "240/240 [==============================] - 0s 229us/step - loss: 4.8905e-06 - categorical_accuracy: 1.0000 - val_loss: 3.0394e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "240/240 [==============================] - 0s 139us/step - loss: 4.7664e-06 - categorical_accuracy: 1.0000 - val_loss: 3.1017e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 4.7788e-06 - categorical_accuracy: 1.0000 - val_loss: 3.0096e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "240/240 [==============================] - 0s 189us/step - loss: 4.7679e-06 - categorical_accuracy: 1.0000 - val_loss: 3.3911e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "240/240 [==============================] - 0s 167us/step - loss: 4.6706e-06 - categorical_accuracy: 1.0000 - val_loss: 3.1758e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "240/240 [==============================] - 0s 146us/step - loss: 4.6303e-06 - categorical_accuracy: 1.0000 - val_loss: 3.0925e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "240/240 [==============================] - 0s 183us/step - loss: 4.5956e-06 - categorical_accuracy: 1.0000 - val_loss: 2.9961e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "240/240 [==============================] - 0s 186us/step - loss: 4.6511e-06 - categorical_accuracy: 1.0000 - val_loss: 2.9823e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "240/240 [==============================] - 0s 223us/step - loss: 4.7028e-06 - categorical_accuracy: 1.0000 - val_loss: 3.3170e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "240/240 [==============================] - 0s 183us/step - loss: 4.5454e-06 - categorical_accuracy: 1.0000 - val_loss: 3.0456e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "240/240 [==============================] - 0s 145us/step - loss: 4.4024e-06 - categorical_accuracy: 1.0000 - val_loss: 2.9836e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "240/240 [==============================] - 0s 154us/step - loss: 4.5200e-06 - categorical_accuracy: 1.0000 - val_loss: 2.9746e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "240/240 [==============================] - 0s 124us/step - loss: 4.4480e-06 - categorical_accuracy: 1.0000 - val_loss: 3.0620e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "240/240 [==============================] - 0s 146us/step - loss: 4.3924e-06 - categorical_accuracy: 1.0000 - val_loss: 2.7360e-04 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/500\n",
      "240/240 [==============================] - 0s 140us/step - loss: 4.2241e-06 - categorical_accuracy: 1.0000 - val_loss: 3.1650e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "240/240 [==============================] - 0s 198us/step - loss: 4.2485e-06 - categorical_accuracy: 1.0000 - val_loss: 3.0427e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "240/240 [==============================] - 0s 209us/step - loss: 4.3055e-06 - categorical_accuracy: 1.0000 - val_loss: 2.9011e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "240/240 [==============================] - 0s 130us/step - loss: 4.1764e-06 - categorical_accuracy: 1.0000 - val_loss: 2.9226e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 4.1347e-06 - categorical_accuracy: 1.0000 - val_loss: 3.1078e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "240/240 [==============================] - 0s 130us/step - loss: 4.1719e-06 - categorical_accuracy: 1.0000 - val_loss: 2.9037e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "240/240 [==============================] - 0s 160us/step - loss: 4.1392e-06 - categorical_accuracy: 1.0000 - val_loss: 2.7970e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 4.2132e-06 - categorical_accuracy: 1.0000 - val_loss: 3.3111e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "240/240 [==============================] - 0s 147us/step - loss: 4.1044e-06 - categorical_accuracy: 1.0000 - val_loss: 2.9836e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "240/240 [==============================] - 0s 144us/step - loss: 4.0979e-06 - categorical_accuracy: 1.0000 - val_loss: 2.8360e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "240/240 [==============================] - 0s 224us/step - loss: 4.2102e-06 - categorical_accuracy: 1.0000 - val_loss: 2.9165e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "240/240 [==============================] - 0s 151us/step - loss: 4.0002e-06 - categorical_accuracy: 1.0000 - val_loss: 2.7547e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "240/240 [==============================] - 0s 201us/step - loss: 3.9762e-06 - categorical_accuracy: 1.0000 - val_loss: 2.5971e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "240/240 [==============================] - 0s 191us/step - loss: 4.0701e-06 - categorical_accuracy: 1.0000 - val_loss: 3.0996e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "240/240 [==============================] - 0s 208us/step - loss: 3.9549e-06 - categorical_accuracy: 1.0000 - val_loss: 2.9216e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "240/240 [==============================] - 0s 287us/step - loss: 3.8283e-06 - categorical_accuracy: 1.0000 - val_loss: 2.8324e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "240/240 [==============================] - 0s 233us/step - loss: 3.8139e-06 - categorical_accuracy: 1.0000 - val_loss: 2.8722e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "240/240 [==============================] - 0s 150us/step - loss: 3.7414e-06 - categorical_accuracy: 1.0000 - val_loss: 2.8585e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "240/240 [==============================] - 0s 220us/step - loss: 3.7920e-06 - categorical_accuracy: 1.0000 - val_loss: 2.7777e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "240/240 [==============================] - 0s 142us/step - loss: 3.6868e-06 - categorical_accuracy: 1.0000 - val_loss: 3.0054e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "240/240 [==============================] - 0s 123us/step - loss: 3.7196e-06 - categorical_accuracy: 1.0000 - val_loss: 2.5789e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "240/240 [==============================] - 0s 188us/step - loss: 3.6614e-06 - categorical_accuracy: 1.0000 - val_loss: 2.8363e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "240/240 [==============================] - 0s 144us/step - loss: 3.6078e-06 - categorical_accuracy: 1.0000 - val_loss: 2.8289e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "240/240 [==============================] - 0s 127us/step - loss: 3.5671e-06 - categorical_accuracy: 1.0000 - val_loss: 2.8807e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "240/240 [==============================] - 0s 138us/step - loss: 3.5735e-06 - categorical_accuracy: 1.0000 - val_loss: 2.6304e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "240/240 [==============================] - 0s 168us/step - loss: 3.5239e-06 - categorical_accuracy: 1.0000 - val_loss: 2.7730e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "240/240 [==============================] - 0s 164us/step - loss: 3.4623e-06 - categorical_accuracy: 1.0000 - val_loss: 2.8093e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "240/240 [==============================] - 0s 200us/step - loss: 3.4633e-06 - categorical_accuracy: 1.0000 - val_loss: 2.6521e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "240/240 [==============================] - 0s 243us/step - loss: 3.5377e-06 - categorical_accuracy: 1.0000 - val_loss: 2.8223e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "240/240 [==============================] - 0s 167us/step - loss: 3.4210e-06 - categorical_accuracy: 1.0000 - val_loss: 2.7801e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "240/240 [==============================] - 0s 288us/step - loss: 3.3545e-06 - categorical_accuracy: 1.0000 - val_loss: 2.8797e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "240/240 [==============================] - 0s 269us/step - loss: 3.3625e-06 - categorical_accuracy: 1.0000 - val_loss: 2.7831e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "240/240 [==============================] - 0s 147us/step - loss: 3.3709e-06 - categorical_accuracy: 1.0000 - val_loss: 2.6356e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "240/240 [==============================] - 0s 181us/step - loss: 3.2597e-06 - categorical_accuracy: 1.0000 - val_loss: 2.7099e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "240/240 [==============================] - 0s 189us/step - loss: 3.2835e-06 - categorical_accuracy: 1.0000 - val_loss: 2.7252e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "240/240 [==============================] - 0s 206us/step - loss: 3.2944e-06 - categorical_accuracy: 1.0000 - val_loss: 2.7889e-04 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa56e4f22b0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=500, batch_size=20, callbacks=[tensorboard], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[np.argmax(model.predict(X)[233])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_rh.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X)\n",
    "ytrue = np.argmax(y, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[200,   0],\n",
       "        [  0, 100]],\n",
       "\n",
       "       [[200,   0],\n",
       "        [  0, 100]],\n",
       "\n",
       "       [[200,   0],\n",
       "        [  0, 100]]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_rh.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4\n",
    "min_detection_confidence = 0.5\n",
    "min_tracking_confidence = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real time detection and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0d/9g1khm697bqbncyfq3gmq4tc0000gn/T/ipykernel_60781/1752995847.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                           min_tracking_confidence=min_tracking_confidence) as holistic:\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# make detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=min_detection_confidence, \n",
    "                          min_tracking_confidence=min_tracking_confidence) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # make detection\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        \n",
    "        \n",
    "        # perform prediction with relative probability\n",
    "        prediction = labels[np.argmax(model.predict(np.array([points_detection(results)])))]\n",
    "        pred_prob = int(np.max(model.predict(np.array([points_detection(results)])))*100)\n",
    "\n",
    "        print(prediction)\n",
    "        \n",
    "        # add text with prediction\n",
    "        if pred_prob > int(0.01*100):\n",
    "            cv2.putText(frame, f'Lettera: {prediction} ({pred_prob}%)', \n",
    "                        (120,200), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        2 ,\n",
    "                        (0,255,0), \n",
    "                        4, \n",
    "                        cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.putText(frame, f'Lettera: Unknown', \n",
    "                        (120,200), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        2 ,\n",
    "                        (0,255,0), \n",
    "                        4, \n",
    "                        cv2.LINE_AA)\n",
    "\n",
    "        #draw_landmarks_custom(frame, results)\n",
    "  \n",
    "        cv2.imshow('LIS', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
